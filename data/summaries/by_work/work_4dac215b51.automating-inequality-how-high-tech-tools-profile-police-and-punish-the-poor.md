### TITLE
Automating Inequality: How High‑Tech Tools Profile, Police, and Punish the Poor - Virginia Eubanks (St. Martin's Press, 2018)

### OUTLINE NOTES
- **Setting or publication context**
 - Published 2018 amid rapid municipal adoption of data analytics, rising use of predictive algorithms in public services, and growing public debate on surveillance, bias, and criminal justice reform in the U.S.
 - Situated at the intersection of technology studies, social policy critique, and social justice advocacy.

- **Central thesis**
 - **Automated systems used in public services do not merely improve efficiency; they reproduce and amplify existing inequalities.** These systems function as a new form of social sorting - a "digital poorhouse" - that profiles, polices, and punishes low‑income and marginalized people.

- **Core argument / structure**
 - Uses sustained empirical case studies of public‑sector automation to demonstrate patterns and harms:
 - Case studies examine automated eligibility and benefit systems, predictive risk tools in child welfare, and data systems coordinating homelessness services (varied U.S. localities).
 - Shows common mechanisms: data gaps and biases, opaque decision rules, reduced human discretion, and outsourcing of moral accountability to algorithms.
 - Traces consequences: wrongful denials, escalated surveillance, diversion to punitive systems (criminal justice, child removal), and erosion of due process and trust.
 - Argues for systemic remedies: transparency, community control, auditability, and democratic oversight - not just technical fixes.

- **Figures, sources, interlocutors**
 - Empirical sources: FOIA documents, field interviews with social workers, caseworkers, advocacy organizations, and affected persons.
 - Interlocutors include data scientists, municipal officials, privacy and civil‑rights advocates, and critical technology scholars.

- **Doctrines / theological loci treated (implicit or for theological appropriation)**
 - Social justice (preferential treatment of the poor), sin and structural sin, neighborly responsibility, stewardship of power, human dignity (Imago Dei), prophetic critique of institutions, ethics of care vs. technocracy.

- **Closing line (theological center of gravity)**
 - The book issues a prophetic indictment: technological claims to neutrality cloak structural injustice, calling communities of faith and moral thinkers to reclaim accountability, care, and the dignity of the poor from algorithmic governance.

### DISTINCTIVES
- **Unique emphases**
 - Centers the lived experiences of poor and marginalized people subject to automated systems rather than abstract technical critique.
 - Emphasizes bureaucratic design choices and political decisions shaping technologies, not inevitable technical determinism.

- **Corrections or contrasts to predecessors**
 - Counters techno‑utopian narratives that frame automation solely as neutral efficiency or objective fairness.
 - Moves beyond purely statistical critiques by connecting algorithms to policy choices and institutional power.

- **Conceptual or terminological innovations**
 - Popularized the metaphor **"digital poorhouse"** to describe modern systems that surveil and regulate poverty.
 - Frames algorithmic governance as a mode of **social sorting** with moral and civic consequences.

- **Reception and influence**
 - Widely cited across social sciences, tech ethics, and public policy debates; adopted in social ethics and public theology syllabi as an empirical case for critique of technocracy.
 - Influenced advocacy for algorithmic transparency, human oversight, and community data governance.

- **Enduring value**
 - Serves as a durable empirical resource linking technology design to lived injustice; useful for courses in ethics, public theology, and policy.
 - Models interdisciplinary method (FOIA + qualitative interviews + policy analysis) valuable for theological social‑ethics research.

### KEY TERMS & USES
- **Automated decision‑making**
 - Systems that use algorithms to make or recommend public‑benefit decisions (eligibility, risk scores).
- **Digital poorhouse**
 - Metaphor for institutions that surveil, discipline, and manage the poor through digital tools.
- **Predictive risk model**
 - Statistical models that forecast individual risk (e.g., child maltreatment) used to allocate intervention resources.
- **Social sorting**
 - Process by which data and algorithms classify populations and channel resources or sanctions accordingly.
- **Surveillance**
 - Expanded monitoring of poor communities via administrative data, sensors, and interagency data‑sharing.
- **Opacity / Black‑box**
 - Lack of transparency in how algorithms produce outcomes; barrier to accountability and appeal.
- **Data poverty**
 - Missing, skewed, or poor‑quality data about marginalized groups that produces biased outcomes.
- **Erosion of discretion**
 - Reduction of human judgment, often displacing empathy and contextual assessment with algorithmic rules.
- **Due process erosion**
 - Administrative automation undermining procedural safeguards (notice, appeal, meaningful explanation).
- **Accountability deficit**
 - Ambiguity of responsibility when harm results from automated tools (vendor, agency, designer).
- **Auditability / Explainability**
 - Technical and procedural capacities for independent review and explanation of algorithmic decisions.
- **Technocratic governance**
 - Rule by technical experts and metrics rather than democratic deliberation or moral judgment.
- **Human‑in‑the‑loop (critique)**
 - Eubanks problematizes nominal human oversight that is often ineffective or symbolic.
- **Community data governance**
 - Proposed remedy: local control and participatory oversight of data and systems affecting communities.

- **How this work is used across theological loci**
 - As a **definition source** for explaining algorithmic governance, social sorting, and the concept of the "digital poorhouse" in social‑ethics literature.
 - As a **polemic/resource** in public theology and liberation ethics to argue against technocratic solutions that neglect justice, dignity, and accountability.
 - As an **empirical exemplar** for courses on ethics of technology, demonstrating how institutional design impacts theological concerns (neighbor love, structural sin).