### TITLE
**Robot Ethics 2.0: From Autonomous Cars to Artificial Intelligence** - Patrick Lin

### OUTLINE NOTES
- **Setting or publication context:** 
 - Published amid rapid growth in autonomous systems (late 2010s to early 2020s). Interdisciplinary setting: applied ethics, computer science, law, public policy. Not a theological work, but widely read in applied ethics and emerging-technology curricula.
- **Central thesis or doctrinal problem:** 
 - Autonomous technologies force a reconfiguration of moral responsibility, moral agency, and public policy: ethical analysis must move from hypothetical dilemmas to design choices, governance, and distribution of responsibility across human and machine actors.
- **Core argument or structure:** 
 - Surveys concrete domains (autonomous vehicles, care robots, weaponized systems, AI decision-making) to expose recurring ethical problems.
 - Moves from moral puzzles (trolley-like problems) to structural solutions: value-sensitive design, regulation, standards, accountability frameworks.
 - Emphasizes interdisciplinary remedies: engineering practices, legal reform, institutional design, and public deliberation.
- **Figures, sources, interlocutors engaged:** 
 - Philosophers and ethicists (e.g., Allen, Wallach), AI safety thinkers (Bostrom), policy scholars (Ryan Calo), legal theorists; cultural references (Asimov's laws) used as heuristic contrasts.
 - Empirical and technical literature from robotics and computer science informs normative claims.
- **Doctrines treated (theological mapping):**
 - Implicitly engages theological concerns through ethical anthropology and moral responsibility: **personhood, stewardship, agency, sin and culpability (responsibility gaps), justice (distributive effects), and human dignity**.
 - Not a systematic treatment of revelation or classic doctrines (Trinity, Christology) but relevant to practical theology, ethics of care, and ecclesial witness in technology-saturated contexts.
- **Closing line (theological center of gravity):**
 - Robot Ethics 2.0 reframes moral theology for the machine age by shifting attention from abstract moral dilemmas to the ethical architecture of design, governance, and human accountability that protect human dignity and distribute responsibility justly.

### DISTINCTIVES
- **Unique emphases or formulations:**
 - Strong pragmatic pivot: ethical responsibility is embedded in design choices and institutional arrangements rather than resolved purely by individual moral deliberation.
 - Prioritizes **policy and engineering interventions** (standards, audits, requirement specs) alongside philosophical analysis.
- **Corrections or contrasts to predecessors or rivals:**
 - Moves beyond sensationalist framings (AI apocalypse, purely speculative personhood debates) to address immediate, tractable problems (liability, safety, bias).
 - Critiques reliance on thought experiments (trolley problems) when they obscure structural causes and policy levers.
- **Conceptual or terminological innovations:**
 - Popularizes concepts such as **responsibility gap**, **value-sensitive design**, and **meaningful human control** as practical tools for ethics.
 - Emphasizes distributed or collective responsibility models over simple agent-centered accounts.
- **Reception and influence in Reformed and wider theology:**
 - Limited direct incision into confessional dogmatics but significant uptake in practical theology, ethics curricula, and church tech-policy statements.
 - Used by theologians to ground discussions of imago Dei, pastoral care with technology, and social justice impacts of automation.
- **Enduring value for study and teaching:**
 - Models how to translate normative concerns into design and policy proposals; valuable for seminarians and theologians engaging tech ethics, pastoral care, and public theology.
 - Serves as a bridge text for interdisciplinary conversation between theology, ethics, and technical fields.

### KEY TERMS & USES
- **Autonomous vehicle ethics:** Ethical problems specific to self-driving cars (safety trade-offs, decision heuristics, liability).
- **Moral agency (machine vs human):** Distinction between operational autonomy and moral agency; machines may act autonomously without moral personhood.
- **Responsibility gap:** Situations where harms produced by autonomous systems leave unclear who is morally or legally accountable.
- **Value-sensitive design:** Methodology to embed human values into technical design processes.
- **Meaningful human control:** Normative criterion requiring human involvement in critical decision loops to preserve accountability.
- **Distributed responsibility:** Model assigning moral and legal responsibility across designers, deployers, regulators, and users.
- **Machine ethics vs. ethics of machines:** Contrast between programming moral behavior into machines and regulating human behavior around machines.
- **Liability and governance:** Legal frameworks and policy instruments for mediating risks from autonomous systems.
- **Safety engineering:** Technical practices prioritized for risk reduction and moral obligation to protect human life.
- **Bias and fairness in algorithms:** Concerns about discriminatory outcomes and mechanisms for auditing and remediation.
- **Anthropomorphism / personification:** Tendencies to ascribe human traits to robots and the ethical consequences for human relationships.
- **Moral crumple zone:** Concept (from related literature) describing human actors who absorb blame when automated systems fail.
- **Privacy and surveillance:** Trade-offs between data-driven utility and rights to privacy/dignity.
- **Value alignment:** The project of ensuring AI systems' goals track human values-technical and normative challenge.
- **Techno-ethics (public deliberation):** Need for participatory processes to decide ethical trade-offs democratically.

- How this work is used across loci:
 - As a **definition source and conceptual primer** for graduate seminars on applied ethics and technology.
 - As a **case-study and practical model** in pastoral ethics and public theology for addressing institutional responsibility and care.
 - As a **conceptual pivot** for moving discourse from speculative metaphysics of AI to regulatory, design, and justice-oriented interventions.