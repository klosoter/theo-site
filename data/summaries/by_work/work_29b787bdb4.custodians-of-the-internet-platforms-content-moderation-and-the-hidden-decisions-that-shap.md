### TITLE
Custodians of the Internet: Platforms, Content Moderation, and the Hidden Decisions That Shape Social Media - Tarleton Gillespie (Yale Univ. Press, 2018)

### OUTLINE NOTES
- **Setting or publication context**
 - Published 2018 amid intensifying debates about social media, fake news, hate speech, election interference, and calls for platform regulation.
 - Situated within media studies, internet policy, and public-ethics conversations; increasingly taken up by theologians and public theologians concerned with the digital public square.
- **Central thesis or doctrinal problem**
 - Platforms are not neutral conduits but *custodians* whose design choices, rules, and labor practices shape discourse, moral norms, and civic life. The problem: who should steward the online public square and according to what moral and procedural standards?
- **Core argument / structure**
 - Part I: Historical and conceptual framing - emergence of platforms and the promise of neutrality.
 - Part II: How moderation works in practice - policies, takedowns, notice-and-takedown, automated filters, and human moderators.
 - Part III: Institutional pressures - legal constraints, advertisers, user communities, and governments that shape decisions.
 - Part IV: Labor and infrastructure - the hidden, industrialized work of content moderation and its ethical stakes.
 - Part V: Normative implications - transparency, accountability, legitimacy of platforms as governors of speech.
- **Figures, sources, interlocutors engaged**
 - Primary interlocutors: major platforms (Facebook, Twitter, YouTube, Reddit), content moderators, policy teams, technologists, civil-society advocates.
 - Scholarly interlocutors: media theorists, legal scholars, policymakers; indirect dialogue with free-speech advocates and critics of platform power.
- **Doctrines treated (theological reframing)**
 - Authority and stewardship (who governs the commons)
 - Censorship and freedom (limits of speech)
 - Community and communion (formation and policing of publics)
 - Sin, harm, and care (abusive speech, violence, pastoral concerns)
 - Institutional legitimacy and accountability (justice and governance)
- **Closing line (theological center of gravity)**
 - Platforms function as secular custodians with moral agency: their hidden technical and institutional choices enact stewardship over public life and therefore require theological attention to authority, accountability, and care.

### DISTINCTIVES
- **Unique emphases**
 - Focus on moderation as an infrastructural, institutionalized practice rather than isolated incident-driven content removal.
 - Brings labor and human costs to the center: moderation is industrial, often outsourced, emotionally costly work shaping moral outcomes.
- **Corrections or contrasts to predecessors**
 - Challenges claims of platform neutrality and the naive framing of platforms as mere "intermediaries."
 - Moves beyond legal/regulatory binary (free speech vs. censorship) to analyze mundane procedural choices that produce normative effects.
- **Conceptual or terminological innovations**
 - The term **custodian** reframes platforms as active stewards with responsibilities.
 - Emphasizes **proceduralism** and the "hidden decisions" - rule design, enforcement thresholds, and opaque appeals processes.
 - Treats moderation as an assemblage of policy, algorithm, labor, and commercial incentives.
- **Reception and influence**
 - Widely cited across media studies, law, public policy, and ethics; increasingly used in theology courses on digital ethics and public theology.
 - Influenced calls for platform transparency, worker protections for moderators, and rethinking platform accountability mechanisms.
- **Enduring value for study and teaching**
 - Provides a durable analytic vocabulary for assessing platforms' moral authority.
 - Useful case-studies and empirical grounding for seminars on ecclesial presence online, digital pastoral practice, and public theology of communication.

### KEY TERMS & USES
- **Custodian**
 - Platforms conceived as stewards of digital publics; implies moral and procedural duties rather than mere facilitation.
- **Content moderation**
 - Practices and rules for removing, limiting, labeling, or amplifying content; includes both human and algorithmic actions.
- **Platform governance**
 - The institutional arrangements and norms by which platforms regulate speech, behavior, and visibility.
- **Infrastructure**
 - Material and organizational systems (servers, algorithms, moderation teams) that make content governance possible and durable.
- **Community standards**
 - Internal rule-sets that operationalize values (safety, civility, authenticity) and guide moderation decisions.
- **Notice-and-takedown / appeals**
 - Procedural mechanics by which content is reported and contested; key locus of power and legitimacy.
- **Industrial content moderation**
 - The outsourced, large-scale work of human moderators; highlights labor ethics, trauma, and invisibility.
- **Algorithmic curation**
 - Automated ranking and filtering practices that shape visibility and that interact with moderation rules.
- **Proceduralism**
 - Attention to rules, thresholds, and processes rather than only outcomes; central to platform legitimacy.
- **Delegated governance**
 - The shifting of public-regulatory functions to private companies through design and policy choices.
- **Transparency & accountability**
 - Demands for clearer reporting, appeals, and public justification of moderation choices.
- **Public sphere / commons**
 - The theological and civic idea of shared space for speech now materially mediated by platforms.
- **Stewardship (theological import)**
 - Applies ecclesial language to platform responsibility: care for community, protection of vulnerable, and accountability to truth and justice.
- **Harm / safety trade-offs**
 - Conceptualizing moderation as balancing freedom with protection from abuse and misinformation.

- **How this work is used across loci**
 - As a **definition source** for platform governance and content-moderation concepts in ethics and public theology.
 - As a **polemic** against platform neutrality claims; used to argue for theological engagement with digital authority.
 - As an **exegetical/analytic model** for case studies in church digital policy, pastoral care online, and civic formation.
 - As a **conceptual pivot** informing proposals for accountability, transparency, and stewardship frameworks in public theology.