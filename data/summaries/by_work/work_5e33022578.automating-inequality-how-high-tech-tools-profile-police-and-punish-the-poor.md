### TITLE
Automating Inequality: How High-Tech Tools Profile Police and Punish the Poor - Virginia Eubanks (2018)

### OUTLINE NOTES
- **Setting or publication context**
 - Published 2018 amid rising public concern about algorithmic bias, surveillance capitalism, and automated decision systems in the United States.
 - Situated within critical data studies, social justice activism, and interdisciplinary scholarship on technology and poverty.
- **Central thesis or doctrinal problem**
 - **Automated systems - framed as neutral or efficient tools - systematically reproduce and intensify social inequality, especially targeting poor and marginalized populations, thereby functioning as new forms of punishment and exclusion.**
- **Core argument / structure**
 - Empirical case-study approach across municipal, county, and state systems showing recurring mechanisms.
 - Case studies examine automated welfare eligibility and benefits systems, predictive risk models in child welfare, and automated prioritization in homelessness services.
 - Shows how design choices, data gaps, institutional goals (cost-cutting, fraud detection), and vendor practices produce harmful outcomes.
 - Traces how rhetoric of efficiency, objectivity, and scalability masks **moral** and **political** decisions.
 - Argues for democratic accountability, participatory design, and policies that center rights and dignity over algorithmic efficiency.
- **Figures, sources, interlocutors engaged**
 - Draws on interviews with affected people, public records, vendor documents, and secondary literature in surveillance studies and algorithmic accountability (dialogue with scholars and activists such as Cathy O'Neil, Frank Pasquale, and others in the critical algorithms field).
 - Engages municipal/state administrators, frontline social workers, and advocates.
- **Doctrines treated (theological reframing)**
 - Not systematic theology, but theological themes are implicit and usable:
 - **Sin and structural evil**: systemic injustices reproduced through technology.
 - **Justice and punishment**: administrative systems performing punitive functions.
 - **Human dignity and agency**: dehumanization via datafication and loss of discretion.
 - **Providence and stewardship**: questions about governance, responsibility, and care for the poor.
- **Closing line (theological center of gravity)**
 - Technology that claims neutrality often cloaks moral choices; resisting a digital "poorhouse" is thus a theological demand to restore dignity, accountability, and solidarity to governance.

### DISTINCTIVES
- **Unique emphases**
 - Centers the lived experience of poor people as primary evidence, not abstract metrics.
 - Treats automated systems explicitly as mechanisms of social control and punishment, not merely tools with technical flaws.
 - Links everyday bureaucratic automation to long histories of institutional poverty management (poorhouses, welfare surveillance).
- **Corrections or contrasts to predecessors**
 - Moves beyond algorithmic fairness framings that focus narrowly on statistical bias to emphasize **political economy**: who builds systems, for what institutional ends, and how they intersect with austerity.
 - Contrasts technocratic reformism that assumes better models suffice; insists structural change and democratic oversight are necessary.
- **Conceptual / terminological innovations**
 - Popularized the phrase **"digital poorhouse"** to describe systems that algorithmically segregate, surveil, and punish the poor.
 - Emphasizes **automation-as-punishment** and the concept of **administrative violence** enacted through software.
- **Reception and influence**
 - Widely cited across tech ethics, public policy, social work, and progressive theology; used by activists and scholars to argue for stronger regulation and public oversight.
 - Influential in conversations linking algorithmic governance to abolitionist, Catholic social teaching, and liberation theological critiques of structural sin.
- **Enduring value**
 - Serves as a durable empirical resource connecting abstract critiques of algorithmic bias to tangible harms.
 - Valuable for interdisciplinary courses on ethics, public theology, social welfare, and technology policy.

### KEY TERMS & USES
- **Automated decision systems (ADS)** - software systems that make or aid decisions about individuals (eligibility, risk scores, prioritization).
- **Digital poorhouse** - shorthand for institutional ecosystems that use data and automation to surveil, exclude, and discipline poor people.
- **Predictive risk modeling** - statistical techniques used to forecast individuals' likelihood of involvement in negative outcomes (e.g., child welfare interventions); criticized for reproducing bias.
- **Algorithmic punishment** - the process by which algorithmic outputs produce deprivations, sanctions, or exclusions that function like punitive measures.
- **Welfare surveillance** - the monitoring practices embedded in benefit administration that gather data and trigger interventions.
- **Administrative violence** - harm produced by bureaucratic processes, intensified when those processes are automated and opaque.
- **Feedback loops** - mechanisms where system outputs reshape data inputs (e.g., policing data leads to more policing in the same communities).
- **Opacity / accountability gap** - lack of transparency about models, data, and decision rules that blocks democratic oversight.
- **Cost-cutting logic** - institutional prioritization of savings/efficiency that shapes system design and harms users.
- **Data poverty / representational harms** - how the poor are both underrepresented in datasets and misrepresented by proxies, yielding unfair outcomes.
- **Dehumanization through digitization** - loss of human discretion, narrative, and advocacy when people become records and scores.
- **Vendorization of governance** - outsourcing crucial public functions to private tech firms with misaligned incentives.
- **Austerity as infrastructure** - the claim that budgetary retrenchment sets the conditions for punitive automation.
- **Democratic design** - proposed remedy emphasizing participatory, rights-based system governance.
- **Ethical solidarity** - theological-political call to center dignity and neighbor-love in design and policy.

- **How this work is used across loci**
 - As a **definition source** for terms like "digital poorhouse" and "algorithmic punishment" in ethics and public theology syllabi.
 - As a **polemic** and empirical foundation in public theology and social ethics to argue for policy reform, oversight, and reparative measures.
 - As an **exegetical model** for reading bureaucratic practices through theological lenses of sin, punishment, and care.
 - As a **conceptual pivot** in technology policy debates to move conversations from narrow fairness metrics toward structural accountability and democratic control.