### TITLE
AI as an extractive industry that reorganizes power, labor, and the planet against the myth of disembodied intelligence.

### PREVIEW NOTES
- **Contemporary political economy of AI**, shaped by the 2010s rise of **big data**, **deep learning**, and **platform capitalism** across academia and industry ties at **Microsoft Research** and the **NYU AI Now Institute**.
- **Critical data studies method** with **genealogy**, **STS**, **media archaeology**, and **materialist political economy**, combining **infrastructural analysis** with **visual culture** and fieldwork.
- **Atlas of AI** 2021, **Anatomy of an AI System** 2018, **Excavating AI** 2019, **AI Now Reports** 2016 to 2018, **The Trouble with Bias** NIPS keynote 2017.
- **Central categories** include **extraction**, **classification regimes**, **benchmark ideology**, **data colonialism**, **resource realism**, **planetary computation**, **mythology of AI**.
- **Key interlocutors** and influences include **Ruha Benjamin**, **Safiya Noble**, **Virginia Eubanks**, **Shoshana Zuboff**, **Bruno Latour**, **Donna Haraway**, **Heidegger**, **Langdon Winner**, with artistic collaborations with **Vladan Joler** and **Trevor Paglen**.
- Reformed reception cue: test her **critique of extraction** by **cultural mandate**, **imago Dei**, **idolatry of technique**, **principalities and powers**, **Sabbath-limit**, and **sphere sovereignty**.

### ESSAY
#### 1. Formation, setting, and the problem of power in computation
The Australian-born scholar **Kate Crawford** emerged as a leading voice in the 2010s conversation on the politics of **artificial intelligence**, locating AI within the wider regimes of **capital, labor, and planetary resources**. Her appointments at **Microsoft Research** in New York and her cofounding of the **AI Now Institute** at New York University in 2017 positioned her at the key fault line where **industry research**, **public policy**, and **academic critique** intersect. That institutional location sharpened her signature thesis that AI must be read as a **socio-technical system** that operates through **extraction** of minerals, energy, data, and human attention. Against popular narratives that treat AI as disembodied and immaterial, she insists on **materiality and infrastructure**. The result is a form of **critical data studies** indebted to **STS** and the **political economy of technology**, that re-narrates AI as a field of **power**, not merely an ensemble of algorithms.

Crawford’s early career in media and communication studies in Australia trained her to see **platforms**, **data flows**, and **user practices** as embedded in larger structures of **governance** and **market power**. By the mid 2010s, as **deep learning** models began to dominate benchmark tasks, Crawford redirected attention from model internals to **supply chains**, **labor arrangements**, and **ecological costs**. Her method is genealogical in the mode of **Foucault**, yet anchored in empirical mapping akin to **media archaeology** and **actor-network tracing** from **Bruno Latour**. She borrows from **critical race theory** and **feminist STS** to expose how **classification systems** encode **racialized and gendered power**, while also deploying a situated **visual culture** lens in collaboration with artists. Where much AI ethics traded in **fairness, accountability, and transparency**, Crawford calls for **structural analysis** that interrogates actors, assets, and laws, not only metrics.

#### 2. Method: materialist cartography of AI’s infrastructures
Crawford’s epistemic stance is a **materialist cartography** that seeks to render visible the hidden infrastructures by which **planetary computation** operates. She argues that AI works through **resource realism** rather than disembodied cognition, drawing on **lithium extraction**, **rare earth mining**, **data center energy**, **logistics**, and **waste streams**. The method refuses **computational exceptionalism** and treats machine learning as a site where **classification** and **measurement** serve regimes of **governance**. She pairs **genealogy** with **case studies** to show how categories migrate from **biometrics** and **phrenology** to **facial recognition**, and from **colonial catalogues** to **training datasets**. This method produces a theological analog of sorts for those who study **principalities and powers**, since her analysis captures how ostensibly neutral tools become **normative orders** that discipline bodies and lands.

A hallmark of Crawford’s method is the mapping of the **circuit of extraction**. She tracks three interlinked layers: the **geology of AI** that mines the earth for metals and energy, the **labor of AI** that requires data labeling, moderation, and manufacturing, and the **data of AI** that feeds models drawn from public and private archives. Each layer has its own **sites of injury**. Mining regions face water scarcity and toxic waste, workers face precarious subcontracting and surveillance, and data subjects experience **asymmetric capture** and **classification harms**. The conceptual engine is the link between **classification** and **domination**. Naming is never innocent. Crawford shows that labels and benchmarks are **instruments of ordering**, not neutral mirrors of reality.

#### 3. Anatomy of an AI System: from smart speaker to planetary costs
The collaboration **Anatomy of an AI System**, produced with **Vladan Joler** in 2018, is a visual and analytic map of the **Amazon Echo** that functions as a microcosm of the entire AI regime. The work traces the device from **mines and smelters** through **assembly plants** to **cloud infrastructures**, and finally to **e-waste** and **regulatory gaps**. The project stages an argument about **oikonomia**, the householding of resources, across a planetary scale. It shows how a seemingly benign **voice assistant** relies on **extractive frontiers** in South America, Africa, and East Asia, and on **precarious labor** such as data annotation and content moderation. The map links **trade routes**, **intellectual property**, and **regulatory arbitrage** into a single picture of **AI as political economy**.

Theologically sensitive readers will hear in this anatomy a critique of a secular **dominium** without *telos*. The device is not simply an artifact but a node in a **sacrificial economy** where certain regions and workers bear the costs of convenience for others. Crawford names this as **externalization of harms**. The diagram becomes a catechism in **materialized morality**, teaching that attention to **places, bodies, and ecologies** is indispensable for any meaningful **ethics of technology**. The argument rebukes a gnostic myth that intelligence floats free of creation, insisting on the **creaturely limits** of energy and land.

#### 4. Excavating AI: classification, images, and epistemic violence
With **Trevor Paglen**, Crawford published **Excavating AI** in 2019, a forensic inquiry into the **training images** and **taxonomies** that power computer vision. The essay dissects datasets such as **ImageNet** and **Tiny Images**, showing how **labels** are shot through with **racist slurs**, **gender stereotypes**, and **folk classifications** that migrate into model behavior. The focus is the **politics of classification**, a theme with long theological resonance from **naming in Genesis** to the **ordo of natural law**, here reframed through **critical race** and **feminist** lenses. The pair argue that classification regimes organize the world by **force and fiction**. Once embedded in benchmarks, these labels become a **hard law** that secures research prestige and product claims.

Crawford identifies **benchmark ideology** as a key driver of AI culture. Competitions and leaderboards turn complex social domains into **proxy tasks** with **narrow metrics**, which incentivizes **dataset laundering** and **goal displacement**. The result is a field that confuses incremental metric gains with **knowledge** and **justice**. Interlocutors like **Ruha Benjamin** and **Safiya Noble** deepen this analysis by noting how **race** and **gender** are not neutral features to be recognized but outcomes of **power-laden histories**. **Joy Buolamwini** and **Timnit Gebru** expose **disparate error rates** in facial analysis, which for Crawford exemplify how **classification harms** fall along existing lines of **inequality**. The conceptual lesson is that data are not given but **taken**, and that categories are not discovered but **imposed**.

#### 5. Atlas of AI: the thesis of extraction against the myth of intelligence
Crawford’s major monograph **Atlas of AI** appeared in 2021 and offers a sustained narrative that AI is neither artificial nor intelligent but an **industrial system** driven by **extraction**. The book proceeds geologically, economically, and juridically. She begins with **lithium** in Chile and Nevada and **rare earths** in Inner Mongolia to show that computing rests on **finite resources** and creates **toxic legacies**. She then examines **labor** from **Foxconn assembly** lines to **Amazon Mechanical Turk**, describing a global **just-in-time workforce** that renders AI possible through **annotation**, **moderation**, and **repair**. Finally she surveys **data** as a frontier of **enclosure**, where **platforms** capture public life and convert it into **assets** through expanding **intellectual property** and **terms of service**.

The book also interrogates **military contracts**, **border technologies**, and **biometric governance**, arguing that AI consolidates **state and corporate power** through regimes of **surveillance** and **prediction**. She analyzes the **carbon cost** of large models and data centers, warning about the **energy curve** of **planet-scale computation**. Theologically adjacent themes include the demystification of **technological soteriology**, the idea that computation will deliver a secular **salvation** from scarcity or social conflict. Crawford identifies **mythologies of AI** that promise **omniscience**, **omnibenevolence**, or **omnipotence** through data, which echo a counterfeit **theology of attributes** without **holiness** or **judgment**. Her alternative is not ascetic renunciation but **political regulation**, **labor protections**, **ecological accounting**, and **epistemic humility**.

#### 6. Institutions, policy, and the limits of fairness as a frame
Through the **AI Now Institute**, Crawford helped shift discourse from individual **bias** to **structural accountability**. The **AI Now Reports** from 2016 to 2018 survey **public sector automation**, **workplace surveillance**, **biometric systems**, and the governance challenges of **machine learning**. The reports emphasize conflict of interest in **industry-funded research**, advocating for **independence** and **transparency** in AI policy. In her 2017 **NIPS keynote The Trouble with Bias**, Crawford argued that bias mitigation is inadequate without an analysis of **power**, **context**, and **institutional responsibility**. This line of work influenced efforts to **ban or restrict facial recognition**, require **impact assessments**, and explore **algorithmic audits** in municipal and national policy.

The policy stance remains deeply critical of **tech solutionism**. Rather than treating harms as bugs to be patched by better metrics, Crawford insists on **domain withdrawal** where deployment is unacceptable, such as **affect recognition** and **predictive policing**. She also highlights **labor rights** for data workers and moderators and calls for **climate disclosures** by data centers and model training regimes. The frame of **accountability** is thus broadened to include **legal liability**, **collective bargaining**, and **public oversight**. The conceptual payoff is that AI is governed not by technical expertise alone but by **democratic deliberation** over **ends and limits**.

#### 7. Concepts for theology: idolatry, powers, and the anthropology of attention
Although not a theologian, Crawford’s analysis offers resources for **theological anthropology**, **hamartiology**, and **public theology of technology**. Her critique of the **myth of disembodied intelligence** functions as an anti-gnostic affirmation of **creaturely limits**, which resonates with **creation** and **incarnation** doctrines that bind knowledge to **bodies** and **places**. Her portrait of AI as **extraction** discloses a structural **sin** that subordinates land and labor to **instrumental rationality**, which parallels the biblical account of **idolatry** where images demand sacrifices. The **mythologies of AI** she catalogs perform the role of **false soteriologies**, promising peace or mastery through **calculation** rather than **justice** or **reconciliation**.

Crawford’s attention to **classification** also invites reflection on the **power of naming**. In Scripture, naming can bless or curse. In modern AI, naming becomes a **technology of governance** that fixes people under **labels** for enforcement, exclusion, or monetization. The critique of **benchmark ideology** suggests a displaced **telos**, where the end of inquiry is not truth about reality but victory on a leaderboard. Theologically this is a disordered *ordo amoris*, a love of performance that eclipses **wisdom**. Her emphasis on **labor** and the **dignity of workers** connects to doctrines of **vocation** and **Sabbath**, underscoring the need for **rest** and **limits** in a culture of perpetual optimization.

#### 8. Interlocutors and intellectual debts
Crawford’s corpus dialogues with **Heidegger’s** analysis of **enframing** as the essence of modern technology, yet she resists Heidegger’s abstraction by concreting the analysis in **supply chains** and **policy**. **Langdon Winner’s** claim that **artifacts have politics** is a clear backdrop, as is **Bruno Latour’s** tracing of networks and **Donna Haraway’s** insistence on **situated knowledges**. With **Shoshana Zuboff**, she shares a concern for **surveillance capitalism**, though Crawford probes further into **geology** and **labor**. With **Ruha Benjamin** and **Safiya Noble**, she aligns on the **racialized effects** of **classification** and **search**, and with **Virginia Eubanks** on the use of automation in **welfare** and **criminal justice**. Artistic collaborations with **Vladan Joler** and **Trevor Paglen** give her work a **visual hermeneutic**, translating critical claims into **cartographies** and **image forensics**.

Crawford also speaks into debates within AI ethics itself. She is skeptical of **proceduralist fixes** that bracket political economy and urges a turn toward **abstention** where harms are non-remediable. She contests **technological determinism** by showing the contingency of **datasets**, **benchmarks**, and **institutions**, even as she acknowledges the **path dependence** of standardization. The upshot is a method that refuses **essences** and instead follows **practices, pipelines, and power**. While not offering a metaphysics, her work supplies thick descriptions that disciplines like **political theology** and **ethics** can receive and reframe within more explicitly **normative doctrines**.

#### 9. Strengths and open questions
The strength of Crawford’s project is the relentless centering of **materiality**, **labor**, and **ecology** in the story of **AI**, which counters the distortions of **AI hype** and **digital idealism**. She redeploys **genealogy** not as cynicism but as a discipline of historical memory that prevents **amnesia** about the costs of convenience. Her account of **classification** is precise and well evidenced, showing how **taxonomy** and **benchmarking** become techniques of **power**. The public impact of her work, through **AI Now** and collaborations with journalists and artists, advances **institutional reform** and **regulatory imagination**.

Open questions remain. Crawford’s critique sometimes risks a **totalizing suspicion** that treats AI as a unified regime of **domination** rather than a differentiated field with **plural goods** as well as harms. Her normative horizon is framed by **justice**, **rights**, and **ecology**, yet it leaves less developed a positive account of **human creativity**, **techné**, and **craft** as gifts to be ordered rather than merely constrained. There is also a tension between calls for **abstention** in certain domains and the practical necessity of **triage** in public policy where harms and benefits are mixed. Finally, while she foregrounds **collective action** and **law**, the account of **formation** and **virtue** at the level of persons and professions is relatively thin, which invites complementary work in **ethics of character**.

#### 10. Reformed and WTS evaluation
From a classical Reformed perspective shaped by **creation**, **fall**, **redemption**, and **consummation**, Crawford’s critique of **extraction** names with prophetic clarity the distortion of the **cultural mandate** into **domination** without **stewardship**. Her demystification of the **myth of disembodied intelligence** aligns with the Reformed insistence on **creaturely finitude**, **embodiment**, and **common grace** that enables legitimate **techné** under God’s **providence**. The exposure of **classification regimes** as instruments of **power** mirrors the doctrine of **idolatry** in which human fabrications claim **omniscience** and demand **sacrifice**. Yet the Reformed tradition would press beyond immanent critique toward a thicker **teleology** of technology under the **lordship of Christ**, ordered by **lex charitatis**, the law of love, and disciplined by **Sabbath** as a creation limit. Where Crawford opts for **abstention** and **regulation**, a Reformed account adds **covenantal stewardship**, **sphere sovereignty** in the Kuyperian sense to restrain overreach by state or firm, and a theology of **vocation** that forms artisans, engineers, and legislators in prudence. Her structural analysis of **principalities and powers** can be received as a diagnosis of systemic **sin**, yet Reformed theology will resist collapsing nature into fall, insisting on the goodness of **creation** and the possibility of **reform** through truthful speech, just law, and neighbor love. The constructive alternative is not optimism about **progress**, but a cruciform practice of innovation measured by fidelity to **imago Dei**, justice for the weak, and the peace of the city within the *saeculum*, under the Word that judges the idols of **technique** and frees human work for service.

### RECAP NOTES
- **Setting**: 2010s to 2020s rise of **big data**, **deep learning**, and **platform capitalism**, with roles at **Microsoft Research** and the **NYU AI Now Institute**.
- **Core problem**: demystify AI by exposing **extraction** across **land, labor, and data**, against the **myth of disembodied intelligence**.
- **Major works**: **Atlas of AI** 2021, **Anatomy of an AI System** 2018, **Excavating AI** 2019, and **AI Now Reports** 2016 to 2018, plus the **NIPS 2017** keynote on **bias**.
- **Distinctive positions**: focus on **materiality and infrastructure**, critique of **classification** and **benchmark ideology**, advocacy for **abstention**, **regulation**, and **labor rights**.
- **Interlocutors**: engagement with **Ruha Benjamin**, **Safiya Noble**, **Virginia Eubanks**, **Shoshana Zuboff**, **Heidegger**, **Latour**, **Haraway**, and collaborators **Vladan Joler** and **Trevor Paglen**.
- **Reformed critique**: affirm her unveiling of **idolatry of technique** and **structural sin**, while supplying **teleology**, **covenantal stewardship**, **Sabbath-limit**, and **sphere sovereignty** under **imago Dei**.
- **Legacy**: repositioned AI ethics toward **political economy**, **ecology**, and **labor**, shaping policy debates on **facial recognition**, **accountability**, and the **planetary costs** of computation.