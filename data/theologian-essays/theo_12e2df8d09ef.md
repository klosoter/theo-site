### TITLE
Artificial agents are artifacts, not persons; moral responsibility remains human and institutional.

### PREVIEW NOTES
- **Contemporary AI ethics** in the post-2000s landscape of **cognitive science**, **policy advisory**, and **platform capitalism**, formed across **MIT**, the **University of Bath**, and the **Hertie School**, amid debates on **EU electronic personhood** and **OECD AI Principles 2019**.
- Method marked by **behavior-oriented design**, **Dennettian intentional and design stances**, **naturalistic social-contract ethics**, and a governance-first focus on **accountability and liability**.
- Key works: **Intelligence by Design** 2001 dissertation; **Robots Should Be Slaves** 2010; **Patiency Is Not a Virtue** 2018; **Against Electronic Personhood** open letter 2017; **The Artificial Intelligence of the Ethics of Artificial Intelligence** 2019.
- Central terms: **agency vs patiency**, **artifact not person**, **anthropomorphism critique**, **alignment as governance**, **transparency and auditability**, **concentration of power**.
- Interlocutors and influences: **Daniel Dennett**, **Herbert Simon**, **Rodney Brooks**, **Nick Bostrom**, **Luciano Floridi**, **Shannon Vallor**, **EU Parliament and OECD**.
- Reformed cue: alignment on **imago Dei** and **creator-creature distinction**, cautions about **idolatry of artifacts**, critique of **social-contract moral ontology** and **reductionist naturalism** in light of **covenant and natural law**.

### ESSAY
Joanna J. Bryson emerges as a leading voice in contemporary debates where **artificial intelligence**, **moral agency**, and **social governance** intersect. Her enduring thesis is concise and polemical: **artificial agents are artifacts, not persons**, therefore **moral responsibility** and **liability** must be assigned to humans and institutions that design, deploy, and profit from them. Formed within late twentieth-century **cognitive science** and early twenty-first-century **AI engineering**, Bryson studied and worked across **MIT** and later the **University of Bath**, before relocating to the **Hertie School** in Berlin, contributing also to **OECD AI Principles 2019** and EU-level consultations on **robot personhood**. Against the allure of metaphysical speculation about machine minds, she advances a pragmatist program that treats **ethics as governance** and **design**, not as an ontological upgrade of tools into persons. Her polemical essay **Robots Should Be Slaves** from 2010 crystallized this stance, refracting a technical career in **behavior-oriented design** through a public argument about **responsibility**, **ownership**, and **anthropomorphism**.

Bryson’s method is recognizably **Dennettian** and **Simonian**. From **Daniel Dennett** she appropriates the **design stance** and **intentional stance** as explanatory heuristics for complex behavior, insisting that seeing a system as agent-like does not entail **personhood** or **moral status**. From **Herbert Simon** she absorbs **bounded rationality** and the **artifact perspective**: intelligence is often modular and satisficing, engineered to environments under constraints. Her early academic work, including the 2001 dissertation **Intelligence by Design**, developed **behavior-oriented design** architectures for complex adaptive agents, echoing **Rodney Brooks** on embodiment and reactive systems. These engineering convictions fund her ethics. She reads the recent AI boom not as the birth of alien minds but as a sociotechnical escalation of **optimization, data extraction, and control**, where the decisive variables are **institutional incentives**, **regulatory regimes**, and **product liability**. Her epistemic stance is **naturalistic** and **instrumentalist**: talk of values must cash out as **governance mechanisms** and **accountability structures** that shape incentives *ex ante* and assign penalties *ex post*.

The conceptual core of Bryson’s program compresses into a few high-contrast distinctions. First, **agency vs patiency**: something can perform complex tasks under goal-directed architectures without thereby qualifying as a **moral patient** to whom duties are owed. Second, **artifact not person**: the social category of person is reserved for entities embedded in human moral community by birthright or covenant, not fabricated tools, however sophisticated. Third, **anthropomorphism critique**: the human propensity to project **intentions**, **feelings**, and **dignity** onto artifacts must be treated as a design and regulatory risk, since it invites perverse attributions of **trust** and **moral standing** where they do not belong. Finally, **alignment as governance**: she reconceives **AI alignment** from speculative attempts to ensure benevolent machine goals, toward **institutional alignment** that constrains developers, deployers, and states by **transparency**, **auditability**, and **liability**. Theologically adjacent terms like **imago Dei** and **human dignity** are not her idiom, yet her distinctions press directly on those loci by challenging any substrate-neutral extension of **personhood** to synthetic systems.

The 2010 essay **Robots Should Be Slaves** became a metonym for Bryson’s ethics of artifacts. The provocation is not an endorsement of chattel slavery but a demand that we name robots as **owned tools** for which owners bear **full responsibility**. In her analysis, the vocabulary of **slavery** exposes two hazards. First, we risk morally laundering exploitation by pretending robots are **employees** or **partners**, thereby eroding workers’ rights and obscuring employer culpability when harm occurs. Second, we risk diverting **compassion** and **legal protection** away from vulnerable humans if we dilute **rights discourse** to encompass machines. The essay’s rhetoric drew predictable fire for its historical associations, yet its analytical claim stands: the status of AI must be settled in **property law** and **product liability**, not in **personhood law**. The response to critics sharpened her case that the legal category of **electronic personhood**, then mooted in European policy, would function in practice as a **liability shield** for corporations rather than as genuine moral recognition for artifacts that cannot suffer.

A companion argument reached full cry in the 2018 piece widely discussed under the title **Patiency Is Not a Virtue**. Bryson asserts that cultivating emotional responses toward machine simulacra of pain or need is not itself ethically praiseworthy. **Moral patiency** should track beings capable of genuine **suffering** and **flourishing**, not the persuasive user interfaces of **social robots**. Elevating machine patiency invites two correlated harms. It can intensify **anthropomorphic attachment**, which designers may exploit for **commercial manipulation**. It can also rationalize public policies that standardize **care labor** offloaded to robots, further displacing the human-to-human obligations of **solidarity** and **justice**. Beneath these specific claims stands a general principle Bryson repeats across venues: **rights are institutional instruments** for distributing protection and duty within a human moral ecology, not metaphysical seals of personhood that can be awarded to artifacts by analogy. In theological register, one could say she guards the *ordo amoris* by resisting the idolatrous pull to treat **simulacra** as neighbors to be loved.

At the meta-level, Bryson’s 2019 programmatic essay **The Artificial Intelligence of the Ethics of Artificial Intelligence** argues that the ethics conversation itself must be made **machine-intelligible** enough to be implemented as **governance-by-design**. Rather than abstract debates about **utilitarian** or **deontological** supremacy, she calls for institutional standards that require **transparency**, **documentation**, **impact assessment**, and **auditable controls**. She links this to the emergence of **OECD AI Principles 2019** and related guidelines, highlighting that ethics only binds behavior when embedded in **law**, **procurement**, and **corporate compliance**. In this framework, **alignment** means aligning incentives so that developers and deployers are better off building systems that respect **privacy**, **fairness**, and **safety** than they are cutting corners. Bryson reframes the specter of **superintelligence** as a sociological distraction. The authentic risks are mundane and systemic: runaway **optimization** that erodes agency, **surveillance infrastructures** that concentrate power, and **opacity** that prevents redress.

These meta-ethical convictions underwrite Bryson’s policy interventions, especially her opposition to EU proposals for **electronic personhood** in 2017. The open letter she helped animate warned that creating a new class of **synthetic legal persons** would perversely reduce corporate accountability. It would allow firms to instantiate **limited liability** in swarms of software agents, diffusing responsibility when harms arise. She urges instead that we use familiar legal tools: assign **strict liability** where appropriate, mandate **traceability**, and maintain clear lines from artifact action to human principals. Subsequent essays in 2019 on the **past decade and future of AI’s social impact** emphasize that AI’s greatest danger is its role as a force multiplier for **platform capitalism** and **state surveillance**, not its putative autonomy. Here her interlocutors include **Nick Bostrom** and **Luciano Floridi**, with whom she shares an interest in societal-level consequences but from whom she diverges in metaphysical posture. Where **Bostrom** theorizes **superintelligence** and existential risk, Bryson insists on **institutional design** and ordinary accountability. Where **Floridi** draws an ontology of the **infosphere**, she remains parsimonious, declining to universalize informational being into a new moral community.

The anthropological edge of Bryson’s ethics sharpens when set against the Christian doctrines of **imago Dei** and **human dignity**. By design, her view locates moral status in **biological life** and **social contract**, not in raw **cognitive capacity** or **problem-solving performance**. She denies that high **IQ** or fluent language in an AI system comes close to the metaphysical or moral category of **person**, because the latter is not a function of representational richness but of membership in a human moral order and vulnerability to **harm**. The tradition’s account of the human as **animal rationale** with a transcendent *telos* sits awkwardly with her reductive reading of intelligence as **engineered behavior**. Yet she is close to scriptural reserve when she warns against **anthropomorphism** and the seductions of **idolatry**, a lesson traceable to the Decalogue’s prohibition of **graven images**. For Bryson, machines are precisely images: **simulacra** of agency that should serve, not rule. Theology might translate her point as a defense of the **creator-creature distinction**, reading AI as firmly within human **techne**, not as emergent **spirit**.

Methodologically, Bryson inhabits a fruitful tension that theology can appropriate critically. Her **naturalism** disciplines wishful thinking about AI minds and rebukes the moral sentimentality that confers **patiency** where there is no **soul** or **sentience**. Her **instrumentalism** brings ethics down to **procurement policy**, **audits**, and **liability** where it actually bites, aligning with the Reformed affection for **institutions**, **rules**, and **vocation**. At the same time, a theological account will ask whether her **social-contract** frame can ground **dignity** robustly enough, or whether one needs **lex naturalis** anchored in created order. In dialogue with **Shannon Vallor** on **technomoral virtues** and **Kate Crawford** on **data extractivism**, Bryson’s focus on **accountability** supplies the juridical backbone those more virtue- and power-oriented programs require. Within contemporary **AI ethics**, she stands for an austerely pragmatic current: ethics as **governance-by-design**, with **anthropomorphism** treated as a system-level hazard.

Bryson’s legacy is therefore twofold. Technically, through **behavior-oriented design** and modular architectures she helped normalize the thought that **intelligence** is engineered pattern, not a ghost in the machine. Normatively, through **Robots Should Be Slaves**, **Patiency Is Not a Virtue**, and the **Against Electronic Personhood** interventions, she established a template for resisting the creep of **personhood language** into the artifact domain. Her participation in **OECD AI Principles 2019** and related standards efforts confirms her conviction that future AI ethics will be won or lost in the statutes and audits that govern **deployments** and revenue, not in symposium metaphysics. She dramatizes a principle that theological ethics can translate easily: right worship entails right ordering of tools under **human vocation** and **public justice**.

From a Reformed and Westminster Theological Seminary vantage, Bryson’s program earns strong but qualified affirmation. Her refusal to grant **personhood** to artifacts coheres with the **creator-creature distinction**, and her insistence on **human responsibility**, **institutional accountability**, and **liability** resonates with a covenantal vision of **vocation** under God’s **providence**. Her critique of **anthropomorphism** guards against **idolatry** and the confusion of **simulacra** with neighbors to whom we owe **love**. Yet her **reductionist naturalism** and **social-contract** account of rights leave theological gaps. Reformed orthodoxy would root **dignity** and **duty** in **imago Dei** and **lex naturalis**, not in contingent consensus, and would construe technology within a **creation–fall–redemption** arc rather than as neutral instrument. A covenantal alternative would commend her governance agenda, deepen it by appeal to **sphere sovereignty** and **subsidiarity**, and reframe **alignment** as conforming cultural labor to Christ’s **munus regium**. It would also caution that the rhetoric of **slavery**, even as provocation, risks violating **neighbor-love** and obscuring the church’s historic witness against chattel bondage. With these corrections, Bryson’s core insight stands as a salutary rule of thumb for a Reformed ethics of AI: artifacts serve, image-bearers rule, and responsibility never evaporates into the machine.

### RECAP NOTES
- Setting: **Contemporary AI ethics** shaped by **MIT**, **Bath**, **Hertie**, EU debates on **electronic personhood**, and **OECD AI Principles 2019**.
- Core problem: Distinguishing **artifact** from **person** and securing **human and institutional responsibility** for AI harms.
- Major works: **Intelligence by Design** 2001; **Robots Should Be Slaves** 2010; **Patiency Is Not a Virtue** 2018; **Against Electronic Personhood** 2017; **The Artificial Intelligence of the Ethics of Artificial Intelligence** 2019.
- Defining tools: **agency vs patiency**, **intentional and design stances**, **anthropomorphism critique**, **governance-by-design**, **accountability and liability**.
- Interlocutors: **Dennett**, **Simon**, **Brooks**, **Bostrom**, **Floridi**, **Vallor**, with policy engagement in **EU** and **OECD** arenas.
- Reformed critique: Affirm **creator-creature distinction**, **imago Dei**, and **anti-idolatry**; challenge **social-contract naturalism** with **lex naturalis**, **covenant**, and **sphere sovereignty**; caution on **slavery rhetoric**.
- Legacy: Durable influence on rejecting **robot personhood**, centering **governance** and **liability**, and reframing **alignment** as institutional rather than metaphysical.