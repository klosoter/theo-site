### TITLE
Robots as companion species: analogical, relational ethics that regulate human conduct rather than granting robots moral personhood.

### PREVIEW NOTES
- **Contemporary law-and-technology context** shaped by the post-2010 boom in **AI and social robotics**, the EU debate on **electronic personhood** in 2017, and public HRI experiments exposing **anthropomorphism**.
- **Empirically informed, pragmatist method** that fuses **legal analysis**, **behavioral psychology**, and **relational ethics**, privileging analogy and policy design over metaphysical claims.
- **Key works**: **The New Breed** (2021); widely cited paper **Extending Legal Protection to Social Robots** (2012); public scholarship on **robot rights rhetoric** and **human-robot interaction** across 2012–2024.
- **Central categories**: **companion species analogy**, **anthropomorphism**, **moral patiency vs. moral agency**, **legal personhood**, **virtue formation**, **instrumental vs. relational design**.
- **Interlocutors and influences**: **Sherry Turkle** on **evocative objects**, **Donna Haraway** on **companion species**, **Ryan Calo** on **robot law**, **Lawrence Lessig** on **code as law**, and animal-law debates shaped by **Peter Singer** and successors.
- **Reformed reception cue**: test claims against **imago Dei** uniqueness, **creator-creature distinction**, the **Noahic covenant** and **stewardship**, the **second table** on neighbor-love, and anxieties about **idolatry** and **rights inflation**.

### ESSAY
#### 1. Formation, context, and method
The work of **Kate Darling** belongs to the contemporary convergence of **law, ethics, and robotics**, emerging amid the 2010s surge of **AI** and **social robots** that now populate classrooms, elder care facilities, and homes. Trained in **law** with research appointments in elite technology-policy environments such as the **MIT Media Lab** and the **Berkman Klein Center** at Harvard, Darling operates as a practitioner-scholar whose authority arises from cross-disciplinary fluency. The early twenty-first century witnessed the juridical imagination stretch to accommodate entities like **corporations** and **algorithms**, culminating in the EU Parliament’s 2017 flirtation with **electronic personhood**. Darling’s signature contribution resists that trajectory, offering a **relational ethics** that is empirically informed and normatively minimalist: regulate human behavior toward robots because of what it does to us, not because of what robots are. Her method is a form of **pragmatist analogical reasoning** drawing on **animal law**, **behavioral psychology**, and **human-robot interaction** studies, with controlled emphasis on **anthropomorphism** as a measurable social fact rather than a speculative ontology.

The method is anchored by a twofold conviction. First, **anthropomorphic projection** is a stable and policy-relevant phenomenon; people predictably ascribe **moral patiency** to responsive machines. Second, law is an instrument molded by social practice; therefore **legal categories** should follow our relational entanglements with artifacts rather than force those entanglements into metaphysical fictions like robot **personhood**. In this crucible Darling’s work exhibits the hallmarks of **law-and-technology**: field experiments and case studies are mined for normative purchase, while doctrinal reforms are framed in terms of **harm reduction**, **virtue formation**, and **institutional feasibility**.

#### 2. Major works and the companion species thesis
Darling’s argument reached a wide audience with **The New Breed: What Our History with Animals Reveals about Our Future with Robots** in 2021. The book’s core thesis is analogical and historical: the repertoire humans developed for **animals** as **companions, tools, and co-workers** provides the most productive repertoire for integrating **robots** into society today. Rather than a binary of mere instrument versus person, **The New Breed** retrieves a spectrum of statuses that historically governed human-animal relations: working partners like **horses**, quasi-family **pets**, and regulated laborers that elicited moral concern without conferral of **human rights**. By patterning robots after this plural spectrum, Darling offers middle categories of **care, custody, and use** that avoid the needless inflation of rights while curbing callousness and abuse.

The public experiments that preceded the book made the intuition visceral. Demonstrations with responsive **Pleo** dinosaur robots showed that ordinary participants balk at harming social robots, even when they affirm the machine’s lack of sentience. Darling’s point is not that robots feel pain, but that our treatment of lifelike machines tracks and shapes our treatment of **vulnerable humans and animals**. The legal and ethical analogue is classic: many **animal cruelty laws** historically protected human moral character as much as animals themselves. The upshot is the **companion species analogy** for robots, not to dignify machines as equals, but to design norms that preserve **virtue** and **social trust**.

#### 3. Moral patiency, rights skepticism, and the relational turn
A central conceptual axis in Darling’s work is the distinction between **moral agency** and **moral patiency**. Robots lack moral agency because they lack **intentionality**, **consciousness**, and **accountability** in any non-derivative way. Yet they can function as apparent patients of action because they present as subjects to whom we do things. The immediate temptation is to import **rights talk** to protect these apparent patients. Darling argues this is a category mistake. Rights should track capacities or covenantal relations that carry obligations of justice; robots have neither. What we can and should do is regulate our conduct toward robots due to the foreseeable downstream effects on human persons, especially the formation or deformation of **empathy**.

This **rights skepticism** extends to the legal fantasy of **robot personhood**. Darling notes that such personhood proliferates responsibility gaps. If the robot becomes the legal subject who causes harm, then designers, manufacturers, and operators escape accountability. The more coherent posture is to keep responsibility cemented in the human web through **products liability**, **agency law**, and targeted regulations of **design choices** that manipulate user psychology. Darling thus reframes debates away from metaphysics toward **design ethics** and **institutional responsibility**, a move consistent with **Lawrence Lessig’s** maxim that **code is law** and with **Ryan Calo’s** analyses of robotic embodiment in legal reasoning.

#### 4. Legal design: from cruelty analogies to governance toolkits
Darling’s legal proposals are measured and instrumentally focused. She suggests limited protections for **social robots** that mirror existing **animal welfare** or **cultural property** regimes where the rationale is not intrinsic dignity but the preservation of social goods. Examples include prohibiting public spectacles of robot abuse that normalize cruelty, imposing transparency requirements on **anthropomorphic interfaces**, and regulating **data extraction** in care settings where users form bonds with devices. She proposes that in contexts like **elder care** and **education**, robotic design should aim at augmenting human relationships rather than replacing them, with oversight that attends to **power asymmetries**, **consent**, and **deception**. The standard is not robot rights but **virtuous use** and **harm prevention**, a pattern reminiscent of incremental **administrative law** rather than sweeping constitutional redefinition.

The rejection of **electronic personhood** crystallizes in her critique of the EU’s 2017 motion proposing a new legal status for advanced robots. Darling counters that the history of **corporate personhood** shows how artificial entities become shields for evasion when they acquire standing. Better to treat robots as chattels with special handling protocols, or as regulated tools akin to **medical devices**, than as subjects whose putative autonomy legally obfuscates human accountability. The institutions to task are familiar: consumer protection agencies, **tort law**, labor regulators, and sector-specific professional bodies.

#### 5. Labor, economy, and the horse analogy
The economic dimension of **The New Breed** turns on the horse. Just as the motor vehicle displaced working horses across the nineteenth and twentieth centuries, certain robots will displace repetitive human labor. Darling emphasizes that futures are not fated. The historical lesson is that governance decisions mediate whether technological change yields **worker degradation** or **human flourishing**. If robots are framed as collaborators, not cheap replacements, then policy can prioritize **job redesign**, **reskilling**, and the allocation of routine tasks to machines while preserving or elevating **human judgment** and **relational labor**. Theologically adjacent categories lurk here: the dignity of **vocation**, the ordering of **means and ends**, and the **common good**. Darling’s register is secular and policy-oriented, but the ethical thrust is clear: design institutions so that the costs and benefits of automation are justly distributed, and do not let **market incentives** instrumentalize persons.

This labor emphasis tempers naive celebrations of **AI autonomy**. Darling resists narratives that over-ascribe agency to machines because such narratives serve dominant interests that prefer to attribute harmful outcomes to inscrutable systems. By demystifying agency and insisting on traceable lines of responsibility from **dataset curation** to **deployment decisions**, she defends a politics of accountability compatible with **democratic oversight** and responsive regulation.

#### 6. Care, education, and the Turkle debate
In contexts of care and education, Darling engages **Sherry Turkle**’s critique of **evocative objects** and her wariness that social robots substitute simulation for relationship. Darling accepts the caution but rejects the zero-sum conclusion. Under the **companion species analogy**, robotic companions can be like **therapy animals**: not replacements for human intimacy but instruments that catalyze patient engagement, memory recall, or language acquisition. The normative requirement is strict guardrails: transparency about the device’s non-personal nature, constraints on **deceptive design**, user consent, and the refusal to deploy robots where they predictably displace essential human contact.

This is where **anthropomorphism** transitions from bug to feature. Because humans naturally project into responsive artifacts, designers must channel that projection toward therapeutic ends while preventing exploitation. Darling’s emphasis on **relational ethics** thus converges with **virtue ethics**: policy should cultivate empathy, patience, and attentiveness in users, and it should prevent habituation to domination or contempt, particularly in children. By tuning **interface cues** and **interaction scripts**, we can make robots that elicit the best in us, while the law discourages configurations that degrade **moral perception**.

#### 7. Interlocutors and the metaphysical restraint
Darling’s work resonates with **Donna Haraway’s** idiom of **companion species** as well as her earlier **cyborg** reflections, though Darling is more juridically pragmatic and less ontologically expansive. The **Haraway** thread endorses cross-species companionship as a site of mutual becoming; Darling compresses this into policy modules for machines that are not species at all, insisting always that robots are artifacts. With **Bruno Latour** one hears faint echoes of **actor-network theory** in Darling’s attention to how artifacts mediate social relations, though she does not traffic in **quasi-objects** language. In legal scholarship, **Ryan Calo**’s analyses of how robots challenge doctrinal categories are congenial; with **Peter Singer** and later **animal law** theorists she shares a tactical posture of expanding concern without conflating statuses, but she refuses strong utilitarian reductions that collapse qualitative distinctions among beings.

A fixed pole in Darling’s constellation is resistance to **category errors**. Legal personhood is not a metaphysical discovery but a **juridical tool**. Anthropomorphism is not evidence that robots are subjects; it is evidence that humans are relational. This disciplined restraint protects her from the more speculative claims in **transhumanism** and certain philosophical defenses of **AI moral status**. If one day machines achieve functional markers of agency and consciousness, we would then have new facts; Darling’s point is that present facts warrant **behavioral regulation** and **design accountability**, not metaphysical proclamation.

#### 8. Theological traction: anthropology, stewardship, and idolatry
Although Darling writes as a secular ethicist, her proposals intersect directly with classic loci of **systematic theology**. First, **theological anthropology**. By centering human virtue and the fragility of **empathy**, she implicitly honors a thick account of the person as relational, a theme congruent with the **imago Dei** as capacity and vocation for communion. Second, **creation and stewardship**. The analogies to **animals** reactivate the biblical pattern where humans exercise **dominion** as **stewardship**, not domination, toward fellow creatures. Extending this prudential frame to machines does not attribute life to artifacts; it simply guards the steward’s heart against **cruelty** and **callousness** that easily migrate across domains.

Third, **idolatry**. The perennial temptation is to make tools into **quasi-persons** or to mask human sin behind the seeming autonomy of **systems**. Darling’s legal critique of **electronic personhood** functions as a prophylactic against idolatrous attributions. Her insistence on tracing responsibility back to designers and institutions aligns with a theological insistence that humans remain accountable covenant partners, not passive nodes in technological fate. Finally, her proposed governance of **deceptive design** in care settings dovetails with scriptural worries about **false images** that capture the heart; the law should not license architectures of deception that habituate us to love what is not lovable as person.

#### 9. Integrated Reformed/WTS evaluation
From a **Reformed** vantage centered at **Westminster Theological Seminary**, Darling’s project is both illuminating and in need of principled specification. It is illuminating because her **relational ethics** and rejection of **robot personhood** protect the **creator-creature distinction** and the uniqueness of the **imago Dei**. Her empirical case that cruel conduct toward **lifelike artifacts** deforms human character coheres with Reformed attention to the formative power of **habitus**, the **second table** of the law, and the corruption of affections by **idolatry**. Her legal focus on accountability preserves the moral agency of persons and institutions under **common grace** governance, resonating with the **Noahic covenant** as a creational order for civil life. Yet principled specification is needed on two fronts. First, the **animal analogy** must be tethered to a clear hierarchy of being: animals are fellow creatures within God’s providence, while robots are artifacts without breath; any extension of animal-law logics to machines is purely prudential. Reformed theology thus rejects any slide toward intrinsic **moral patiency** in robots and would frame protections strictly as ordinances that safeguard human neighbors and uphold justice. Second, Darling’s measured openness to therapeutic uses of **anthropomorphism** should be chastened by the doctrine of **idol-factory hearts**: even transparent simulations may seduce users into disordered loves. A Reformed alternative sharpens the criteria of use by prioritizing the sanctity of **speech and presence** in covenantal relationships, urging Christian communities to catechize against manipulative designs, while advocating public policies that retain human-to-human ministry in domains of care, education, and worship. In sum, the Reformed response affirms Darling’s **rights skepticism**, **accountability politics**, and **virtue-protective** regulation as expressions of common grace, while insisting that the **imago Dei**, the **two kingdoms** distinction in governance, and the vigilance against **idolatry** set the conceptual rails for engaging social robots without confusion of nature and art.

### RECAP NOTES
- **Setting**: Post-2010 **AI and robotics** expansion, legal flirtations with **electronic personhood**, and public encounters with **anthropomorphic** machines.
- **Core focus**: A **relational ethics** for robots that regulates human conduct and design practices instead of granting **robot rights** or **personhood**.
- **Major works**: **The New Breed** (2021) and the influential paper **Extending Legal Protection to Social Robots** (2012), plus public scholarship on **HRI** and policy.
- **Distinctives**: The **companion species analogy** from **animal law**, emphasis on **moral patiency vs. agency**, and refusal of metaphysical inflation in favor of **legal design** and **virtue formation**.
- **Interlocutors**: Engagement with **Sherry Turkle**, **Donna Haraway**, **Ryan Calo**, **Lawrence Lessig**, and animal-law debates shaped by **utilitarian** and **virtue-ethical** frames.
- **Reformed critique**: Affirm **imago Dei** uniqueness and **creator-creature distinction**, use **Noahic** prudence for civil regulation, resist **idolatry** and intrinsic moral status for artifacts, and prioritize **human accountability**.
- **Legacy**: A durable toolkit in **robot law and ethics** that redirects debates from **rights** to **responsible design**, shaping policy for care, labor, and education in an age of **social robots**.