### TITLE
Technomoral virtue as the moral grammar for human flourishing under algorithmic and robotic power

### PREVIEW NOTES
- **Contemporary philosophy of technology** in a late modern, Silicon Valley and Edinburgh **AI ethics** landscape shaped by **STS** and post-analytic moral theory.
- **Comparative neo-Aristotelian virtue ethics** integrated with **Confucian** and **Buddhist** traditions, drawing on **pragmatism**, **postphenomenology**, and **responsible innovation**.
- **Technology and the Virtues** 2016; **Moral Deskilling and Upskilling in a New Machine Age** 2015; **Social Networking Technology and the Virtues** 2010; editor of **The Oxford Handbook of Philosophy of Technology** 2022; **The AI Mirror** 2024.
- **Technomoral virtues**, **technomoral wisdom** phronesis, **moral deskilling**, **human flourishing**, **sociotechnical imaginaries**, **algorithmic opacity**.
- Dialogues with **Aristotle**, **Confucius**, **Buddha**, **MacIntyre**, **Nussbaum**, **Heidegger**, **Hans Jonas**, **Don Ihde**, **Peter-Paul Verbeek**, debates with **Bostrom** and **Turkle**.
- Reformed cue: test her **eudaimonist teleology**, **anthropology**, and **moral formation** against **creation-fall-redemption**, **noetic effects of sin**, **lex naturae**, and **churchly practices**.

### ESSAY
#### 1. Formation, setting, and methodological stance
Shannon Vallor emerges as a leading voice in the **ethics of technology** in the 2010s and 2020s, moving from Santa Clara University in the heart of **Silicon Valley** to the University of Edinburgh as the **Baillie Gifford Chair in the Ethics of Data and AI** and director of the **Centre for Technomoral Futures**. Her work takes shape amid the turbulence of **algorithmic governance**, **platform capitalism**, and **robotics**, where design choices redistribute practical and moral agency. Against a backdrop of **analytic moral theory** fragmenting into rule and outcome calculations, and a **Science and Technology Studies** tradition attentive to power and mediation, Vallor assembles a synthetic approach that is both normatively thick and empirically literate. The anchoring commitments are to **virtue ethics** as a teleological account of **human flourishing**, to **postphenomenology** as a descriptive discipline of human-technology relations, and to **responsible innovation** as an institutional frame. In this triangulation she engages **Aristotle** on habituated excellence, **Confucius** on relational roles and **li**, and **Buddhist** accounts of desire and **karuna** compassion, while conversing with **MacIntyre** on practices, **Nussbaum** on the capabilities approach, **Heidegger** on enframing Gestell, and **Hans Jonas** on responsibility for technologically extended action.

Vallor’s formation reflects an unusual intimacy with the living laboratories of **platform design** and **automation**, complemented by participation in policy fora and industry advisory roles where **AI ethics** must be translated into governance and engineering heuristics. This setting drives her to a method that refuses both the **technological determinism** of dystopian prophecy and the **techno-solutionism** of venture ideology. Instead she offers a **comparative virtue tradition** suited to a globalized, plural modernity, claiming that thick virtues can be articulated across traditions without imposing a single metaphysical dogma. The result is a moral anthropology centered on plastic but teleologically orientable capacities, a moral epistemology of **phronesis** or **technomoral wisdom**, and a practical program of **moral habituation by design** in sociotechnical systems.

#### 2. Virtue as the grammar of the digital age
The system is elaborated in **Technology and the Virtues** 2016, which advances the thesis that emerging technologies require a renewal and expansion of **virtue ethics** as the only framework supple enough to guide action under pervasive uncertainty. Against **deontology** strapped to fixed rules and **consequentialism** dependent on brittle predictions, Vallor foregrounds **character** as the locus of stability in flux, cultivated through practices that refine perception, desire, and judgment. Her distinctive contribution is the articulation of **technomoral virtues** that name the excellences needed for navigating digital, robotic, and biotechnical affordances. She identifies a family of such virtues, including **honesty**, **self-control**, **humility**, **justice**, **courage**, **empathy**, **care**, **civility**, **flexibility**, **perspective**, **magnanimity**, all ordered by **technomoral wisdom** as the integrative virtue. The point is not to bolt technology onto an old list but to thicken the list through the pressures of new media: **algorithmic opacity** requires a cultivated patience and intellectual humility, **ubiquitous surveillance** requires courage and civility, **global connectivity** requires cross-cultural empathy and care.

The argument is deliberately comparative and cosmopolitan. Vallor retrieves **Aristotelian eudaimonia** as a telos of rational and social flourishing, aligns it with **Confucian ren** as humane excellence enacted through ritual roles, and with **Buddhist** diagnoses of craving and the virtue of **karuna**. This triangulation allows her to resist a narrowly Western **instrumental rationality** and to emphasize relational and affective dimensions of **technomoral formation**. She also explicitly adapts **MacIntyrean practices** to digital life, asking how professional and civic practices can anchor excellence in fields like software engineering and data science, and she appropriates **Nussbaum's capabilities** as a public language for the goods these virtues protect. In every case, the focus is not on deriving duties from first principles but on shaping agents whose **practical wisdom** can improvise the right mean in evolving **sociotechnical imaginaries**.

#### 3. Early diagnoses: social media, habituation, and deskilling
Before the 2016 monograph, Vallor had already lifted key stones in the foundation through **Social Networking Technology and the Virtues** 2010, identifying how platforms like Facebook incline users toward or away from **honesty**, **civility**, and **friendship** as Aristotelian and Confucian goods. She scrutinizes **attention economies** as environments of moral training in which affordances and incentives sculpt the appetites and perceptions that underwrite judgment. This thread culminates in **Moral Deskilling and Upskilling in a New Machine Age** 2015, where she coins and defends the concept of **moral deskilling**: the erosion of practical moral capacities through outsourcing to machines, from GPS to predictive policing and medical decision aids. The contrast, **moral upskilling**, names the intentionally designed reinforcement of virtues through tools that scaffold reflection and accountability.

Here Vallor leverages **postphenomenology** via **Don Ihde** and **Peter-Paul Verbeek** to show that technologies mediate the world to us, amplify some relations and mute others, and so are never morally inert. Combined with **STS** insights about **sociotechnical imaginaries** from scholars like **Sheila Jasanoff**, this entails that every app, platform, and device participates in moral pedagogy. Hence her insistence that **design ethics** not content itself with static checklists but ask formation questions: what habits of attention does this interface reward, what dispositions toward others does this surveillance tool normalize, what picture of the human does this recommender system enact?

#### 4. The AI Mirror: reflection, amplification, and reclamation
Vallor's **The AI Mirror** 2024 extends and sharpens the framework for the age of **machine learning**. The titular metaphor cuts against the rhetoric of alien minds by arguing that contemporary **AI systems** are less autonomous agents than mirrors that reflect, sort, and amplify the patterns of human data, capital, and governance. They are not strangers so much as condensers of our own commitments and blind spots. The explanatory payoff is immediate: harms attributed to the machine are often functions of **training data**, **objective functions**, and **deployment contexts** chosen by humans under institutional pressures. The moral payoff is to shift attention from speculative **superintelligence** debates to the present political economy of AI, where **algorithmic opacity**, **scale**, and **feedback loops** intensify existing social vices.

The book proposes a reclamation project. To avoid becoming captives of our own mirror, institutions must cultivate **technomoral virtues** at three levels: the individual agents who design, deploy, and use AI; the professional and civic practices that sustain **epistemic humility** and **justice** under uncertainty; and the public governance structures capable of resisting **disinformation**, **surveillance capitalism**, and extractive **data colonialism**. Vallor’s tone is neither alarmist nor sanguine; it is **Jonasian responsibility** modulated for learning systems. She resists **Heideggerian fatalism** about enframing by insisting on the plasticity of mediation and on the possibility of **moral upskilling** through evaluation, audit, and redesign. The mirror metaphor also functions as an anthropology: AI returns us to ourselves and exposes the need for deliberate cultivation of **technomoral wisdom** in collective settings.

#### 5. Comparative interlocutors and contested alternatives
Vallor’s interlocutors illustrate the hybridity of her method. From **Aristotle** she borrows the structure of **virtue and phronesis**, yet she refuses a closed polis by incorporating **Confucian li** and **Buddhist mindfulness** as resources for **self-control** and **care** in networked life. From **MacIntyre** she draws the notion that **practices** generate standards of internal goods and excellences that can discipline professions like **software engineering** against corrosive external goods. From **Nussbaum** she appropriates the **capabilities approach** to name public goods protected by technomoral design, such as bodily integrity, play, affiliation, and control over one’s environment. From **Hans Jonas** she draws the asymmetry of risk in technoscientific action and the need for a **principle of responsibility** extended across time.

Against these, she contends with thinkers who either inflate or deflate technological agency. She reads **Heidegger** as warning rightly of **enframing** yet errs, in her judgment, by neglecting the plural and revisable character of mediations demonstrated by **postphenomenology**. She disputes **Bostromian** focus on existential risk from superintelligence by redirecting moral attention to harm already at work in **biased classifiers** and **weaponized attention**. She advances beyond **rule-based machine ethics** by rejecting the fantasy of encoding **deontology** into systems without cultivating the **virtues** of their human architects and institutions. These contrasts underscore her core claim: only a program of **character formation** across sociotechnical systems can sustain a future worth wanting.

#### 6. Institutionalization: from classroom to lab to law
Crucial to Vallor’s project is an institutional imaginary for **responsible innovation**. She proposes that universities, companies, and governments embed **technomoral virtues** into curricula, design lifecycles, and oversight. In education, this means cultivating **practical wisdom** through case-based learning, cross-cultural ethics, and exposure to **STS** analyses of power rather than segregating ethics as a compliance module. In engineering practice, it means integrating **iterative reflection**, **value-sensitive design**, and **red-teaming** of harms so that teams can avoid **moral deskilling** through overreliance on automation. In governance, it means developing **auditability**, **transparency**, and **accountability** regimes that empower democratic correction and **civic virtues** like informed trust and dissent.

Her editorial work on **The Oxford Handbook of Philosophy of Technology** 2022 consolidates this agenda by curating a field where metaphysics, ethics, and policy interpenetrate. The volume displays the breadth of **philosophy of technology**, from classic **Heideggerian** themes to contemporary debates over **AI**, **biotech**, and **environmental technologies**, and it positions **virtue ethics** as a live option. By moving deftly between **theory** and **practice**, Vallor’s institutional strategy refuses a dichotomy between micro-morality of agents and macro-morality of structures, instead proposing the co-formation of persons and polities through **technomoral design**.

#### 7. Anthropological and teleological commitments
At the heart of Vallor’s system is a constructive **anthropology**. Humans are plastic, social, desiring, and teachable; technologies are not external tools but elements of our **second nature** that mediate perception and habit. The telos, articulated in terms of **human flourishing**, is immanent and this-worldly, even when enriched by **Confucian** and **Buddhist** visions of relational harmony and liberation from craving. The metaphysics remains restrained: she declines explicit theological or metaphysical commitments beyond the claim that virtues shape agency toward recognizable goods in any viable polity. Her **epistemology of phronesis** acknowledges fallibility and the need for **humility** under uncertainty. Her **moral psychology** foregrounds attention, affect, and habituation, especially under the distortions of **algorithmic personalization** and **gamified reward schedules**.

The net effect is an ethics built for late modern conditions: plural, global, technologically saturated, and uncertain. The wager is that **technomoral virtues** can be named and taught without a single substantive account of the highest good, that public consensus on **capabilities** and shared vulnerabilities suffices to stabilize norms. The price of this wager is that virtues can sometimes look freestanding, unmoored from a metaphysical soil, though Vallor tries to mitigate this by reaching across **Aristotelian**, **Confucian**, and **Buddhist** canons. Yet the wager also liberates her to converse across ideological divides in **industry**, **policy**, and **civil society**, where thick but accessible languages of **care**, **justice**, and **wisdom** can travel.

#### 8. Case domains: automation, care, and platforms
Vallor’s proposals are concrete in domains where **moral deskilling** threatens to hollow out agency. In **automation**, she warns of **automation complacency** and loss of **situational awareness**, urging designs that keep humans meaningfully in the loop, not as rubber stamps but as cultivated practitioners capable of override and inquiry. In **care robotics**, she tracks how carebots risk simulating **empathy** without building mutual **care**, proposing guardrails so that human caregivers are upskilled by robotic assistance rather than replaced. In **platform governance**, she dissects how **recommender systems** train appetites, polarize civility, and reward performative self-branding, and she urges architectural changes that scaffold **honesty** and **civility** over **engagement maximization**. Each domain demonstrates the same thesis: moral quality in a technological age is inseparable from the **habituation** that designs elicit.

These analyses also showcase her use of **sociotechnical imaginaries** to reveal the futures implicit in design. A predictive policing system enacts a political imaginary about risk and order; a large language model enacts an imaginary about language, agency, and knowledge. By making these imaginaries explicit, Vallor asks developers and publics to deliberate about the **teloi** they embed and the **virtues** they thereby train or corrode. The goal is reflexive **technomoral wisdom** at scale, not merely after-the-fact risk management.

#### 9. Influence, reception, and internal tensions
By 2024, Vallor is a touchstone in **AI ethics**, **design ethics**, and **virtue theory** applied to technology. Her language of **technomoral virtues** is adopted in curricula, professional standards, and think tanks seeking alternatives to checklist ethics. She has helped relocate the center of gravity from speculative apocalypse to the lived **moral pedagogy** of everyday technologies. Interdisciplinary respect follows from her facility with **STS**, **postphenomenology**, and policy processes, and from her willingness to press **industry** toward **accountability** while offering tractable practices for **moral upskilling**.

Yet tensions remain. The comparative virtue method must navigate risks of selective syncretism that flatten **Confucian** and **Buddhist** distinctives into an **Aristotelian** frame. The reliance on an immanent **eudaimonism** and **capabilities** may be too thin for deep normative disagreement, particularly where **surveillance capitalism** or **data colonialism** are legitimated by democratic processes. And technomoral formation by design courts paternalism: which **virtues**, whose **flourishing**, decided by what authorities? Vallor acknowledges these perils, insisting on **civic virtues** like dissent and on transparent, participatory governance. Still, the constructive burden is heavy: to stabilize thick virtue without a shared metaphysic in a fractured polity.

#### 10. Reformed and WTS evaluation
From a classical **Reformed** vantage, Vallor’s project earns strong commendation for recovering **virtue**, **phronesis**, and **habit** against reductive rule- and outcome-ethics, and for exposing the formative power of **technological liturgies**. Her sensitivity to **institutional sin** in **platform capitalism** and to **postphenomenological mediation** resonates with **noetic effects of sin** and the critique of **idolatry** lodged against **technological determinism** and **market providence**. Yet three principled tensions stand out. First, the teleology of **human flourishing** lacks a **Christological telos** and the eschatological contour of **creation-fall-redemption-consummation**; without the grammar of **covenant** and **beatific vision**, technomoral virtue risks settling for an immanent peace too modest for the depth of human longing and too fragile before death and injustice. Second, her anthropology trusts the educability of desire through public formation but underestimates radical **concupiscence** and **bondage of the will**; **moral upskilling** by design is necessary but not sufficient absent **regeneration** and the sanctifying work of the Spirit that reorders loves. Third, authority over virtue formation is lodged in plural institutions without a theologically normed **lex naturae** and **special revelation**, risking a proceduralism that can catechize vice under democratic consent. A Reformed alternative would affirm her **common grace** insights, receive **technomoral virtues** as civic excellences, and then thicken them by locating technology within the **cultural mandate**, ordering design to **love of God and neighbor** under **law and gospel**, and centering the **church as formative polis** whose **Word and sacrament** recalibrate attention, desire, and judgment. This supplies an ontological telos, a hamartiology equal to the stakes of **algorithmic power**, and a hope robust enough to resist despair and triumphalism alike.

### RECAP NOTES
- **Silicon Valley to Edinburgh** context; **AI ethics** in a world shaped by **platform capitalism**, **STS**, and **postphenomenology**.
- Core problem: how to secure **human flourishing** under **algorithmic** and **robotic** mediation through **technomoral virtues** and **phronesis**.
- Major works: **Technology and the Virtues** 2016; **Moral Deskilling and Upskilling** 2015; **Social Networking Technology and the Virtues** 2010; editor of **Oxford Handbook of Philosophy of Technology** 2022; **The AI Mirror** 2024.
- Distinctives: **technomoral virtues**, **technomoral wisdom**, **moral deskilling/upskilling**, **responsible innovation**, **sociotechnical imaginaries**.
- Key interlocutors: **Aristotle**, **Confucius**, **Buddha**, **MacIntyre**, **Nussbaum**, **Heidegger**, **Hans Jonas**, **Ihde**, **Verbeek**; debates with **Bostrom** and **Turkle**.
- Reformed take: affirm **virtue formation** and critique of **determinism**, but press for **creation-fall-redemption**, **noetic effects of sin**, **Christological telos**, **churchly formation**, and **love-of-God-and-neighbor** as technology’s governing norm.
- Legacy: a widely adopted **virtue framework** for **AI ethics** and **design**, shaping curricula, policy, and practice while provoking debate over the metaphysical grounding of public **flourishing**.