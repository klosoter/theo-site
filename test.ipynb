{
 "cells": [
  {
   "metadata": {},
   "cell_type": "code",
   "source": "",
   "id": "2c8ecc8291f922e2",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "len(updated_topics)",
   "id": "c55eba4d79e27d8",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "import os, json, pathlib, re\n",
    "from flask import Flask, jsonify, send_from_directory, request, abort\n",
    "from markdown import markdown\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()\n",
    "ROOT = pathlib.Path(\".\").parent.resolve()\n",
    "DATA_DIR = pathlib.Path(os.getenv(\"DATA_DIR\", ROOT / \"data\")).resolve()\n",
    "\n",
    "app = Flask(__name__, static_folder=str(ROOT / \"static\"))  # assets served at /static\n",
    "\n",
    "\n",
    "# ---------- helpers ----------\n",
    "def _load_json(path: pathlib.Path, default=None):\n",
    "    try:\n",
    "        with path.open(\"r\", encoding=\"utf-8\") as f:\n",
    "            return json.load(f)\n",
    "    except FileNotFoundError:\n",
    "        return default\n",
    "\n",
    "\n",
    "def _resolve_outlines_dir():\n",
    "    # 1) explicit env wins\n",
    "    env_path = os.getenv(\"OUTLINES_DIR\")\n",
    "    if env_path:\n",
    "        return pathlib.Path(env_path).resolve()\n",
    "    # 2) data/outlines if present\n",
    "    data_out = DATA_DIR / \"outlines\"\n",
    "    if data_out.exists():\n",
    "        return data_out.resolve()\n",
    "    # 3) fallback project-root /outlines\n",
    "    return (ROOT / \"outlines\").resolve()\n",
    "\n",
    "\n",
    "OUTLINES_DIR = _resolve_outlines_dir()\n",
    "\n",
    "CACHE = {\n",
    "    \"topics\": _load_json(DATA_DIR / \"topics.json\", []),\n",
    "    \"theologians\": _load_json(DATA_DIR / \"theologians.json\", []),\n",
    "    \"works\": _load_json(DATA_DIR / \"works.json\", []),\n",
    "    \"by_topic\": _load_json(DATA_DIR / \"indices\" / \"by_topic.json\", {}),\n",
    "    \"by_theologian\": _load_json(DATA_DIR / \"indices\" / \"by_theologian.json\", {}),\n",
    "    \"by_work\": _load_json(DATA_DIR / \"indices\" / \"by_work.json\", {}),\n",
    "    \"search\": _load_json(DATA_DIR / \"indices\" / \"search_index.json\", []),\n",
    "    \"topic_mapping\": _load_json(ROOT / \"topic_mapping_updated.json\", {})\n",
    "}"
   ],
   "id": "145ec1c2ec0c5daf",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "works = CACHE[\"works\"]\n",
    "work_canon_map = []\n",
    "for work in works:\n",
    "    work_canon_map.append({\"work_id\": work[\"id\"], \"canonical_id\": work[\"id\"]})\n",
    "\n",
    "\n",
    "# with open(\"data/work_canon_map.json\", \"w\", encoding=\"utf-8\") as f:\n",
    "#     json.dump(work_canon_map, f, ensure_ascii=False, indent=2)"
   ],
   "id": "c1a7ecaded4638c0",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "with open(\"data/work_canon_map.json\", \"r\", encoding=\"utf-8\") as f:\n",
    "    work_canon_map = json.load(f)\n",
    "\n",
    "len(work_canon_map), len({w[\"canonical_id\"] for w in work_canon_map})"
   ],
   "id": "5c8d7e73538ba678",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "",
   "id": "ea91fe6a10e8a014",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "",
   "id": "57f6837fc2bc0dae",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "topic_mapping = CACHE[\"topic_mapping\"]\n",
    "by_work = CACHE[\"by_work\"]\n",
    "works_json = CACHE[\"works\"]"
   ],
   "id": "1196ee145626cb50",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-19T19:21:55.953664Z",
     "start_time": "2025-08-19T19:21:55.743307Z"
    }
   },
   "cell_type": "code",
   "source": [
    "#!/usr/bin/env python3\n",
    "import os, json, pathlib, datetime, shutil\n",
    "\n",
    "load_dotenv()\n",
    "ROOT = pathlib.Path(\".\").parent.resolve()\n",
    "DATA_DIR = pathlib.Path(os.getenv(\"DATA_DIR\", ROOT / \"data\")).resolve()\n",
    "\n",
    "def _load_json(path: pathlib.Path, default=None):\n",
    "    try:\n",
    "        return json.loads(path.read_text(encoding=\"utf-8\"))\n",
    "    except FileNotFoundError:\n",
    "        return default\n",
    "\n",
    "\n",
    "def _read_jsonl(p):\n",
    "    try:\n",
    "        lines = p.read_text(encoding=\"utf-8\").splitlines()\n",
    "    except FileNotFoundError:\n",
    "        return []\n",
    "    out = []\n",
    "    for line in lines:\n",
    "        line = line.strip()\n",
    "        if not line:\n",
    "            continue\n",
    "        try:\n",
    "            out.append(json.loads(line))\n",
    "        except Exception:\n",
    "            pass\n",
    "    return out\n",
    "\n",
    "\n",
    "def _write_json(path: pathlib.Path, obj):\n",
    "    ts = datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
    "    if path.exists():\n",
    "        backups = path.parent / \"backups\"\n",
    "        backups.mkdir(parents=True, exist_ok=True)\n",
    "        shutil.copy2(path, backups / f\"{path.name}.bak-{ts}\")\n",
    "    path.write_text(json.dumps(obj, ensure_ascii=False, indent=2), encoding=\"utf-8\")\n",
    "\n",
    "\n",
    "def _write_jsonl(path: pathlib.Path, obj):\n",
    "    ts = datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
    "    if path.exists():\n",
    "        backups = path.parent / \"backups\"\n",
    "        backups.mkdir(parents=True, exist_ok=True)\n",
    "        shutil.copy2(path, backups / f\"{path.name}.bak-{ts}\")\n",
    "    path.write_text(\"\\n\".join(json.dumps(r, ensure_ascii=False) for r in obj) + \"\\n\", encoding=\"utf-8\")\n",
    "\n",
    "\n",
    "CACHE = {}\n",
    "\n",
    "WORK_FILE = DATA_DIR / \"works.json\"\n",
    "WORK_CANON_MAP = DATA_DIR / \"work_canon_map.json\"\n",
    "TOPIC_FILE = DATA_DIR / \"topics.json\"\n",
    "THEO_FILE = DATA_DIR / \"theologians.json\"\n",
    "AUTHORS_REGISTRY = DATA_DIR / \"authors_registry.json\"\n",
    "OUTLINES_JSONL = DATA_DIR / \"outlines.jsonl\"\n",
    "\n",
    "TOPIC_WORK_EDGES = DATA_DIR / \"indices/topic_work_edges.json\"\n",
    "SEARCH_INDEX = DATA_DIR / \"indices/search_index.json\"\n",
    "BY_WORK = DATA_DIR / \"indices/by_work.json\"\n",
    "BY_TOPIC = DATA_DIR / \"indices/by_topic.json\"\n",
    "BY_TOPIC_KEYWORKS = DATA_DIR / \"indices/by_topic_key_works.json\"\n",
    "BY_THEO = DATA_DIR / \"indices/by_theologian.json\"\n",
    "\n",
    "TOPIC_MAPPING = ROOT / \"topic_mapping_updated.json\"\n",
    "\n",
    "def _reload():\n",
    "    CACHE[\"works\"] = _load_json(WORK_FILE, [])\n",
    "    CACHE[\"works_canon_map\"] = _load_json(WORK_CANON_MAP, [])\n",
    "    CACHE[\"topics\"] = _load_json(TOPIC_FILE, [])\n",
    "    CACHE[\"theologians\"] = _load_json(THEO_FILE, [])\n",
    "    CACHE[\"authors_registry\"] = _load_json(AUTHORS_REGISTRY, {})\n",
    "    CACHE[\"outlines\"] = _read_jsonl(OUTLINES_JSONL)\n",
    "    CACHE[\"topic_work_edges\"] = _load_json(TOPIC_WORK_EDGES, [])\n",
    "    CACHE[\"by_work\"] = _load_json(BY_WORK, {})\n",
    "    CACHE[\"by_topic\"] = _load_json(BY_TOPIC, {})\n",
    "    CACHE[\"by_topic_key_works\"] = _load_json(BY_TOPIC_KEYWORKS, {})\n",
    "    CACHE[\"by_theologian\"] = _load_json(BY_THEO, {})\n",
    "    CACHE[\"search_index\"] = _load_json(SEARCH_INDEX, [])\n",
    "    CACHE[\"topic_mapping\"] = _load_json(TOPIC_MAPPING, {})\n",
    "\n",
    "\n",
    "def _slugify(s: str) -> str:\n",
    "    s = unicodedata.normalize(\"NFKD\", s or \"\")\n",
    "    s = s.encode(\"ascii\", \"ignore\").decode(\"ascii\").lower()\n",
    "    s = re.sub(r\"[^a-z0-9]+\", \"-\", s).strip(\"-\")\n",
    "    return re.sub(r\"-{2,}\", \"-\", s)\n",
    "\n",
    "_reload()\n",
    "\n",
    "\n",
    "works           = CACHE[\"works\"]\n",
    "# work_canon_map = CACHE[\"work_canon_map\"]\n",
    "topics         = CACHE[\"topics\"]\n",
    "theologians     = CACHE[\"theologians\"]\n",
    "authors_registry= CACHE[\"authors_registry\"]\n",
    "topic_work_edges = CACHE[\"topic_work_edges\"]\n",
    "outlines        = CACHE[\"outlines\"]\n",
    "by_work         = CACHE[\"by_work\"]\n",
    "by_topic        = CACHE[\"by_topic\"]\n",
    "by_topic_key_works = CACHE[\"by_topic_key_works\"]\n",
    "by_theologian   = CACHE[\"by_theologian\"]\n",
    "search_index    = CACHE[\"search_index\"]\n",
    "topic_mapping  = CACHE[\"topic_mapping\"]"
   ],
   "id": "1b279916eccc31f2",
   "outputs": [],
   "execution_count": 34
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-19T19:22:52.550686Z",
     "start_time": "2025-08-19T19:22:52.546792Z"
    }
   },
   "cell_type": "code",
   "source": [
    "for t in theologians:\n",
    "    if \"Johnson\" in t[\"name\"]:\n",
    "        print(t[\"id\"], t[\"name\"])\n",
    "        # break"
   ],
   "id": "ebc605aaab60553f",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "theo_421f6f1cf18d Adam C. Johnson\n",
      "theo_3698ee84fe2f Adam J. Johnson\n",
      "theo_15f0416eb31e Keith E. Johnson\n",
      "theo_7fb613bf3367 Keith L. Johnson\n",
      "theo_c015821b2f38 Marcus Peter Johnson\n"
     ]
    }
   ],
   "execution_count": 38
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-19T21:40:16.517244Z",
     "start_time": "2025-08-19T21:40:16.513032Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import json, pathlib, textwrap, itertools, collections\n",
    "DATA = pathlib.Path(\"data\")  # adjust if different\n",
    "\n",
    "def load_json_maybe_txt(path: pathlib.Path):\n",
    "    \"\"\"\n",
    "    Reads JSON from .json or .txt. Returns None if missing/invalid.\n",
    "    \"\"\"\n",
    "    for p in (path, path.with_suffix(\".txt\")):\n",
    "        if p.exists():\n",
    "            try:\n",
    "                return json.loads(p.read_text(encoding=\"utf-8\"))\n",
    "            except Exception as e:\n",
    "                print(f\"Failed to parse {p.name}: {e}\")\n",
    "    print(f\"Missing: {path.name} (and {path.with_suffix('.txt').name})\")\n",
    "    return None\n",
    "\n",
    "def head(x, n=3):\n",
    "    if isinstance(x, list):\n",
    "        return x[:n]\n",
    "    if isinstance(x, dict):\n",
    "        return dict(itertools.islice(x.items(), n))\n",
    "    return x\n"
   ],
   "id": "9a6e4148995d814e",
   "outputs": [],
   "execution_count": 41
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-19T21:42:16.933087Z",
     "start_time": "2025-08-19T21:42:16.797793Z"
    }
   },
   "cell_type": "code",
   "source": [
    "topics          = load_json_maybe_txt(DATA / \"topics.json\") or load_json_maybe_txt(DATA / \"topics\")\n",
    "theologians     = load_json_maybe_txt(DATA / \"theologians.json\") or load_json_maybe_txt(DATA / \"theologians\")\n",
    "works           = load_json_maybe_txt(DATA / \"works.json\") or load_json_maybe_txt(DATA / \"works\")\n",
    "by_topic        = load_json_maybe_txt(DATA / \"indices\" / \"by_topic.json\") or load_json_maybe_txt(DATA / \"by_topic\")\n",
    "by_theologian   = load_json_maybe_txt(DATA / \"indices\" / \"by_theologian.json\") or load_json_maybe_txt(DATA / \"by_theologian\")\n",
    "by_work         = load_json_maybe_txt(DATA / \"indices\" / \"by_work.json\") or load_json_maybe_txt(DATA / \"by_work\")\n",
    "search_index    = load_json_maybe_txt(DATA / \"indices\" / \"search_index.json\") or load_json_maybe_txt(DATA / \"search_index\")\n",
    "canon_map_raw   = load_json_maybe_txt(DATA / \"work_canon_map.json\") or load_json_maybe_txt(DATA / \"work_canon_map\")\n",
    "\n",
    "summary = {\n",
    "    \"topics\": (type(topics).__name__, 0 if topics is None else len(topics)),\n",
    "    \"theologians\": (type(theologians).__name__, 0 if theologians is None else len(theologians)),\n",
    "    \"works\": (type(works).__name__, 0 if works is None else len(works)),\n",
    "    \"by_topic\": (type(by_topic).__name__, 0 if by_topic is None else len(by_topic)),\n",
    "    \"by_theologian\": (type(by_theologian).__name__, 0 if by_theologian is None else len(by_theologian)),\n",
    "    \"by_work\": (type(by_work).__name__, 0 if by_work is None else len(by_work)),\n",
    "    \"search_index\": (type(search_index).__name__, 0 if search_index is None else len(search_index)),\n",
    "    \"canon_map_raw\": (type(canon_map_raw).__name__, 0 if canon_map_raw is None else (len(canon_map_raw) if isinstance(canon_map_raw, dict) else len(canon_map_raw))),\n",
    "}\n",
    "\n",
    "summary\n"
   ],
   "id": "4850310e8ad2874a",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'topics': ('list', 109),\n",
       " 'theologians': ('list', 514),\n",
       " 'works': ('list', 8225),\n",
       " 'by_topic': ('dict', 109),\n",
       " 'by_theologian': ('dict', 249),\n",
       " 'by_work': ('dict', 8225),\n",
       " 'search_index': ('list', 8982),\n",
       " 'canon_map_raw': ('list', 8225)}"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 43
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-19T21:47:43.284540Z",
     "start_time": "2025-08-19T21:47:43.271400Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def check_required_keys():\n",
    "    problems = []\n",
    "\n",
    "    if not isinstance(topics, list) or not all(isinstance(t, dict) for t in topics or []):\n",
    "        problems.append(\"topics should be a list[dict].\")\n",
    "    else:\n",
    "        req = {\"id\", \"slug\", \"title\"}\n",
    "        missing = [t.get(\"id\") for t in topics if not req.issubset(set(t))]\n",
    "        if missing:\n",
    "            problems.append(f\"topics missing required keys for ids: {missing[:5]}...\")\n",
    "\n",
    "    if not isinstance(theologians, list) or not all(isinstance(t, dict) for t in theologians or []):\n",
    "        problems.append(\"theologians should be a list[dict].\")\n",
    "    else:\n",
    "        req = {\"id\", \"slug\", \"full_name\"}\n",
    "        missing = [t.get(\"id\") for t in theologians if not req.issubset(set(t))]\n",
    "        if missing:\n",
    "            problems.append(f\"theologians missing required keys for ids: {missing[:5]}...\")\n",
    "\n",
    "    if not isinstance(works, list) or not all(isinstance(w, dict) for w in works or []):\n",
    "        problems.append(\"works should be a list[dict].\")\n",
    "    else:\n",
    "        req = {\"id\", \"title\"}\n",
    "        missing = [w.get(\"id\") for w in works if not req.issubset(set(w))]\n",
    "        if missing:\n",
    "            problems.append(f\"works missing required keys for ids: {missing[:5]}...\")\n",
    "\n",
    "    if not isinstance(by_theologian, dict):\n",
    "        problems.append(\"by_theologian should be a dict[theologian_id → {...}].\")\n",
    "    else:\n",
    "        # spot-check outlines shape\n",
    "        for tid, blob in list(by_theologian.items())[:3]:\n",
    "            ob = blob.get(\"outlines_by_topic_category\")\n",
    "            if ob is None:\n",
    "                problems.append(f\"by_theologian[{tid}] missing 'outlines_by_topic_category'.\")\n",
    "\n",
    "    return problems or [\"OK\"]\n",
    "\n",
    "check_required_keys()\n"
   ],
   "id": "2f760cef4195ef87",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['OK']"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 54
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-19T21:47:55.434563Z",
     "start_time": "2025-08-19T21:47:55.430207Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def theologians_with_outline_counts():\n",
    "    counts = []\n",
    "    if not isinstance(by_theologian, dict):\n",
    "        return counts\n",
    "    for tid, blob in by_theologian.items():\n",
    "        ob = (blob or {}).get(\"outlines_by_topic_category\") or {}\n",
    "        total = sum(len(v or []) for v in ob.values())\n",
    "        counts.append((tid, total))\n",
    "    counts.sort(key=lambda x: -x[1])\n",
    "    return counts\n",
    "\n",
    "outline_counts = theologians_with_outline_counts()\n",
    "outline_counts[:10]\n"
   ],
   "id": "2b3ced2447b71bd5",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('theo_09edae13e8c2', 109),\n",
       " ('theo_aff4ec250119', 109),\n",
       " ('theo_124906e9ce1f', 109),\n",
       " ('theo_f0740853d304', 109),\n",
       " ('theo_3fc45f8c5a0a', 109),\n",
       " ('theo_ea6658b8fe68', 109),\n",
       " ('theo_1c0566e3d363', 109),\n",
       " ('theo_888da193d4d0', 109),\n",
       " ('theo_2a4f308c7e0f', 109),\n",
       " ('theo_0967b706d70a', 109)]"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 55
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-19T21:46:33.351927Z",
     "start_time": "2025-08-19T21:46:33.348480Z"
    }
   },
   "cell_type": "code",
   "source": "{i[\"work_id\"]: i[\"canonical_id\"] for i in canon_map_raw} == canon_map",
   "id": "f2adddd3dcb3e4b8",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 53
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-19T21:48:18.579724Z",
     "start_time": "2025-08-19T21:48:18.562053Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Maps for lookup\n",
    "WORK_MAP = {w.get(\"id\"): w for w in (works or []) if isinstance(w, dict)}\n",
    "THEO_MAP = {t.get(\"id\"): t for t in (theologians or []) if isinstance(t, dict)}\n",
    "TOPIC_MAP = {t.get(\"id\"): t for t in (topics or []) if isinstance(t, dict)}\n",
    "\n",
    "from collections import Counter, defaultdict\n",
    "\n",
    "def canon_counts_by_theologian(by_work_index, canon_map):\n",
    "    ctr_by_theo = defaultdict(Counter)\n",
    "    for wid, wdata in (by_work_index or {}).items():\n",
    "        tid = (wdata or {}).get(\"primary_author_theologian_id\")\n",
    "        if not tid:\n",
    "            continue\n",
    "        cid = canon_map.get(wid, wid)\n",
    "        ctr_by_theo[str(tid)][cid] += 1\n",
    "    out = {}\n",
    "    for tid, ctr in ctr_by_theo.items():\n",
    "        def key(pair):\n",
    "            cid, n = pair\n",
    "            title = (WORK_MAP.get(cid) or {}).get(\"title\", cid)\n",
    "            return (-n, title)\n",
    "        out[tid] = sorted(ctr.items(), key=key)\n",
    "    return out\n",
    "\n",
    "def canon_counts_by_topic(topics_list, canon_map):\n",
    "    result = {}\n",
    "    for t in topics_list or []:\n",
    "        kw = (t.get(\"key_works\") or {})\n",
    "        wts = [canon_map.get(w, w) for w in (kw.get(\"wts_old_princeton\") or [])]\n",
    "        rec = [canon_map.get(w, w) for w in (kw.get(\"recent\") or [])]\n",
    "        wts_ctr = Counter(wts)\n",
    "        rec_ctr = Counter(rec)\n",
    "        def sort_ctr(ctr):\n",
    "            items = list(ctr.items())\n",
    "            def key(pair):\n",
    "                cid, n = pair\n",
    "                title = (WORK_MAP.get(cid) or {}).get(\"title\", cid)\n",
    "                return (-n, title)\n",
    "            items.sort(key=key)\n",
    "            return items\n",
    "        result[t[\"id\"]] = {\"WTS\": sort_ctr(wts_ctr), \"Recent\": sort_ctr(rec_ctr)}\n",
    "    return result\n",
    "\n",
    "theo_counts = canon_counts_by_theologian(by_work, canon_map)\n",
    "topic_counts = canon_counts_by_topic(topics, canon_map)\n",
    "\n",
    "len(theo_counts), len(topic_counts), head(theo_counts, 1), head(topic_counts, 1)\n"
   ],
   "id": "3cf25a263238f708",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(514,\n",
       " 109,\n",
       " {'theo_38bdde67d604': [('work_e23a86f8e59e', 7),\n",
       "   ('work_00a7ffbf4f1f', 7),\n",
       "   ('work_164359e1d5eb', 7),\n",
       "   ('work_6e3ad522c1d9', 6),\n",
       "   ('work_4f5d932ee86d', 6),\n",
       "   ('work_7891d069bc45', 3),\n",
       "   ('work_b14d7e28c087', 3),\n",
       "   ('work_3b9bf5607d5b', 2),\n",
       "   ('work_0df6a3008d62', 2),\n",
       "   ('work_43953e5ff021', 2),\n",
       "   ('work_c5945fb05040', 1),\n",
       "   ('work_f73153fa5c01', 1),\n",
       "   ('work_2bd9af54437f', 1),\n",
       "   ('work_df16c5ba1c1e', 1),\n",
       "   ('work_74239522b287', 1),\n",
       "   ('work_5e45c2279463', 1),\n",
       "   ('work_d164ab57d411', 1),\n",
       "   ('work_df0b2de70103', 1),\n",
       "   ('work_bcefacb5aa84', 1),\n",
       "   ('work_ca9641222d99', 1),\n",
       "   ('work_81541116dcf0', 1),\n",
       "   ('work_b14a49c7a811', 1),\n",
       "   ('work_487d92ef2be1', 1),\n",
       "   ('work_2dfd45bba5b6', 1)]},\n",
       " {'top_73dd29f4e3dd': {'WTS': [('work_163d78b8375b', 1),\n",
       "    ('work_db4c1732a6ae', 1),\n",
       "    ('work_ee43657ddf33', 1),\n",
       "    ('work_d10c4faf2802', 1),\n",
       "    ('work_11c15342b809', 1)],\n",
       "   'Recent': [('work_08823315cc21', 1),\n",
       "    ('work_851dd8bc2ea0', 1),\n",
       "    ('work_ade473659f33', 1),\n",
       "    ('work_248778f535b4', 1),\n",
       "    ('work_c45649e6b3d7', 1),\n",
       "    ('work_2e022b6f1cac', 1),\n",
       "    ('work_e252be83634f', 1),\n",
       "    ('work_5d90d4842717', 1),\n",
       "    ('work_dae4d66aa208', 1),\n",
       "    ('work_b30b1a77a931', 1),\n",
       "    ('work_748cd07eddd5', 1),\n",
       "    ('work_bb2956c2e2fe', 1),\n",
       "    ('work_f99cc0f1784d', 1),\n",
       "    ('work_981fae1d407f', 1),\n",
       "    ('work_a94b57cf5efe', 1)]}})"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 56
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-19T21:48:29.223217Z",
     "start_time": "2025-08-19T21:48:29.215918Z"
    }
   },
   "cell_type": "code",
   "source": [
    "problems = []\n",
    "\n",
    "# Are there any theologians referenced in by_work but missing in theologians list?\n",
    "theo_ids_in_by_work = { (v or {}).get(\"primary_author_theologian_id\") for v in (by_work or {}).values() }\n",
    "theo_ids_in_by_work.discard(None)\n",
    "missing_theos = sorted(tid for tid in theo_ids_in_by_work if tid not in THEO_MAP)\n",
    "if missing_theos:\n",
    "    problems.append(f\"Theologian IDs referenced in by_work but not found in theologians: {missing_theos[:10]}...\")\n",
    "\n",
    "# Are there canonical IDs that have no matching entry in works?\n",
    "canon_ids = set(canon_map.values())\n",
    "missing_canon_works = sorted(cid for cid in canon_ids if cid not in WORK_MAP)\n",
    "if missing_canon_works:\n",
    "    problems.append(f\"Canonical work IDs missing in works: {missing_canon_works[:10]}...\")\n",
    "\n",
    "# Are topic key_works referencing unknown IDs?\n",
    "def unknowns_from_topic_keyworks():\n",
    "    unknown = set()\n",
    "    for t in topics or []:\n",
    "        kw = (t.get(\"key_works\") or {})\n",
    "        for wid in (kw.get(\"wts_old_princeton\") or []):\n",
    "            if wid not in WORK_MAP and canon_map.get(wid, wid) not in WORK_MAP:\n",
    "                unknown.add(wid)\n",
    "        for wid in (kw.get(\"recent\") or []):\n",
    "            if wid not in WORK_MAP and canon_map.get(wid, wid) not in WORK_MAP:\n",
    "                unknown.add(wid)\n",
    "    return sorted(unknown)\n",
    "\n",
    "unknown_topic_wids = unknowns_from_topic_keyworks()\n",
    "if unknown_topic_wids:\n",
    "    problems.append(f\"Topic key_works include unknown work ids: {unknown_topic_wids[:10]}...\")\n",
    "\n",
    "problems or [\"No linkage problems detected\"]\n"
   ],
   "id": "bef3204e4429bf77",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['No linkage problems detected']"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 57
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-19T21:48:37.407197Z",
     "start_time": "2025-08-19T21:48:37.401221Z"
    }
   },
   "cell_type": "code",
   "source": [
    "print(\"TOPICS (first 5):\")\n",
    "for t in (topics or [])[:5]:\n",
    "    title = t.get(\"title\")\n",
    "    wts = len((t.get(\"key_works\") or {}).get(\"wts_old_princeton\") or [])\n",
    "    rec = len((t.get(\"key_works\") or {}).get(\"recent\") or [])\n",
    "    print(f\" - {title}  | WTS={wts}  Recent={rec}\")\n",
    "\n",
    "print(\"\\nTHEOLOGIANS (first 5):\")\n",
    "for th in (theologians or [])[:5]:\n",
    "    outlines_total = 0\n",
    "    entry = (by_theologian or {}).get(th.get(\"id\")) or {}\n",
    "    ob = entry.get(\"outlines_by_topic_category\") or {}\n",
    "    outlines_total = sum(len(v or []) for v in ob.values())\n",
    "    print(f\" - {th.get('full_name')}  | outlines={outlines_total}\")\n",
    "\n",
    "print(\"\\nWORKS (first 5):\")\n",
    "for w in (works or [])[:5]:\n",
    "    cid = canon_map.get(w.get(\"id\"), w.get(\"id\"))\n",
    "    alias = \"(alias)\" if cid != w.get(\"id\") else \"\"\n",
    "    print(f\" - {w.get('title')}  [{w.get('id')} → {cid}] {alias}\")\n"
   ],
   "id": "d8659a393a7c5a72",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TOPICS (first 5):\n",
      " - Nature and task of theology  | WTS=5  Recent=15\n",
      " - General and special revelation  | WTS=5  Recent=15\n",
      " - Self-attestation and authority of Scripture  | WTS=5  Recent=15\n",
      " - Inspiration and inerrancy  | WTS=5  Recent=15\n",
      " - Accommodation and incarnational analogy  | WTS=5  Recent=15\n",
      "\n",
      "THEOLOGIANS (first 5):\n",
      " - A. Andrew Das  | outlines=0\n",
      " - A. Edward Siecienski  | outlines=0\n",
      " - A.A. Hodge  | outlines=1\n",
      " - A.T.B. McGowan  | outlines=0\n",
      " - Abraham Kuyper  | outlines=109\n",
      "\n",
      "WORKS (first 5):\n",
      " - \"1–2 Thessalonians\" (IVP New Testament Commentary, 2003)  [work_e0fde1126f74 → work_0df6a3008d62] (alias)\n",
      " - \"A Brief Declaration and Vindication of the Doctrine of the Trinity\"  [work_cfa06cf99d84 → work_2aafa13e949a] (alias)\n",
      " - \"A Brief Declaration and Vindication of the Doctrine of the Trinity\" (for anthropological context)  [work_9a8bad95ad9e → work_2aafa13e949a] (alias)\n",
      " - \"A Brief Instruction in the Worship of God\" (Works, vol. 15)  [work_97263a885a5f → work_beb8536a9f2a] (alias)\n",
      " - \"A Cabinet of Choice Jewels\"  [work_36e4b8f86177 → work_36e4b8f86177] \n"
     ]
    }
   ],
   "execution_count": 58
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-19T21:48:45.924794Z",
     "start_time": "2025-08-19T21:48:45.921871Z"
    }
   },
   "cell_type": "code",
   "source": [
    "spa_datasets_shape = {\n",
    "    \"topics\": isinstance(topics, list),\n",
    "    \"theologians\": isinstance(theologians, list),\n",
    "    \"works\": isinstance(works, list),\n",
    "    \"byTopic\": isinstance(by_topic, dict),\n",
    "    \"byTheo\": isinstance(by_theologian, dict),\n",
    "    \"byWork\": isinstance(by_work, dict),\n",
    "    \"workCanonMap_or_canonMap\": isinstance(canon_map, dict),\n",
    "}\n",
    "\n",
    "spa_datasets_shape\n"
   ],
   "id": "8850ce09f44ade8d",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'topics': True,\n",
       " 'theologians': True,\n",
       " 'works': True,\n",
       " 'byTopic': True,\n",
       " 'byTheo': True,\n",
       " 'byWork': True,\n",
       " 'workCanonMap_or_canonMap': True}"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 59
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-19T21:53:21.732025Z",
     "start_time": "2025-08-19T21:53:21.728683Z"
    }
   },
   "cell_type": "code",
   "source": "len(set(canon_map.values()))",
   "id": "e0b8f7d86c37a7b5",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3447"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 63
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-19T22:06:25.532471Z",
     "start_time": "2025-08-19T22:06:25.519944Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import json, pathlib, re\n",
    "\n",
    "def slugify(name: str) -> str:\n",
    "    \"\"\"Lowercase, replace non-alphanum with hyphens, collapse dashes.\"\"\"\n",
    "    s = name.lower()\n",
    "    s = re.sub(r'[^a-z0-9]+', '-', s)\n",
    "    s = re.sub(r'-+', '-', s).strip('-')\n",
    "    return s\n",
    "\n",
    "# load theologians\n",
    "p = pathlib.Path(\"data/theologians.json\")\n",
    "theologians = json.loads(p.read_text(encoding=\"utf-8\"))\n",
    "\n",
    "# regenerate slugs\n",
    "for t in theologians:\n",
    "    full = t.get(\"full_name\") or t.get(\"name\") or \"\"\n",
    "    t[\"slug\"] = slugify(full)\n",
    "\n",
    "# overwrite file\n",
    "p.write_text(json.dumps(theologians, indent=2, ensure_ascii=False), encoding=\"utf-8\")\n",
    "\n",
    "print(\"Updated slugs for\", len(theologians), \"theologians\")\n",
    "print(\"Example:\", theologians[0][\"full_name\"], \"→\", theologians[0][\"slug\"])\n"
   ],
   "id": "52163c3c3228b5da",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Updated slugs for 514 theologians\n",
      "Example: A. Andrew Das → a-andrew-das\n"
     ]
    }
   ],
   "execution_count": 64
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "3cceaaa3e471589c"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
