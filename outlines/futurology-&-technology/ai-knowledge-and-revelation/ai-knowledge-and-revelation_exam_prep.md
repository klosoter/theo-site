### TITLE
Instrument without Witness: AI, Analogical Knowledge, and the Limits of Revelation

### PREVIEW NOTES
- Core issue: whether artificial intelligence can generate, mediate, or count as knowledge of God, and how AI reshapes the conditions for human knowing of **general** and **special revelation**.
- Decisive figures: Thomas Aquinas, Herman Bavinck, Cornelius Van Til, Alan Turing, Hubert Dreyfus, John Searle.
- Traditions: classical theism and theology of **revelation**; Reformed dogmatics and **analogical knowledge**; philosophy of technology and mind; twentieth-century AI theory and critique.
- Debates:
  - Internal: Reformed disputes on natural theology, **common grace** and cultural mandate, ministerial reason in reading **general revelation** and Scripture.
  - External: computationalism versus phenomenology; naturalism versus theism; realism about intentionality versus eliminativism.
  - Contemporary: large language models, algorithmic opacity, epistemic authority, ecclesial use of AI, data-driven hermeneutics.
- Position: AI is a non-personal artifact lacking intentionality and normativity; it cannot be a source of **revelation** or testimony, though under **common grace** it may serve ministerial functions in inquiry and pedagogy; human knowledge remains covenantal, **analogical**, and Spirit-enabled.

### ESSAY
The governing question is whether artificial intelligence can know, mediate, or reveal, and what its rise requires of a theology of knowledge grounded in the God who speaks. To answer coherently under the canons of classical theism and Reformed dogmatics, we must define AI precisely, situate knowing as a covenantal participation under **special** and **general revelation**, and evaluate machine outputs with respect to intentionality, normativity, and authority. The position defended here is crisp: AI systems are highly capable instruments of pattern formation and manipulation, embedded in human practices, but they lack the intentionality and norm-governed rationality that belong to persons made in the **imago Dei**. They therefore cannot be bearers of revelation or testimony. Properly subordinated as **ministerial reason** within **common grace**, they can aid human inquiry into the created order and service of Scripture’s text, but they neither add to nor constitute **revelation** and must be disciplined by ecclesial criteria of truth, prudence, and charity.

Thomas Aquinas stands at the hinge where theological accounts of knowing and natural cognition become precise. In the Summa Theologiae and De Veritate, Aquinas frames human knowledge as an act of a rational soul immaterially receiving the form of things, abstracted by the agent intellect, under the teleological order of providence. He reformulates Aristotelian potency and act in light of Christian **creation** and **providence**, preserving both the possibility of natural knowledge of God through effects and the irreducible necessity of **special revelation** for knowledge of the Trinity and the economy of salvation. Two features of Aquinas’s method anchor the present question. First, his account of **analogical predication** ensures that language about God is neither univocal nor equivocal, but proportioned from effects to cause such that names are said truly of God according to a mode proper to creatures. Second, his account of **instrumental causality** distinguishes principal cause from instruments whose agency is real but derivative. A quill writes, but not as principal; a prophet speaks, but the Holy Spirit is principal author. These two lines clarify that any artifact, however sophisticated, acts as an instrument within the order of secondary causes. When AI systems produce outputs, they produce signs under human-devised architectures and loss functions; they have operative efficacy but not principal authorship. If an examiner presses whether God could use AI to reveal, the Aquinian answer is yes only in the analogical sense in which God uses creaturely signs as instruments of his self-disclosure. The burning bush could mediate God, but it was not itself the subject who speaks. Revelation is a divine act, not a property of an artifact. Aquinas’s insistence on **divine simplicity** further forecloses confusions: God’s knowledge is identical with his essence and is not discursive. No amount of discursive computation approaches the mode of God’s knowing.

Herman Bavinck extends and reframes these themes for a modern landscape, emphasizing the organic unity of truth and the reciprocity of subject and object under God’s self-revelation. In his Reformed Dogmatics and Philosophy of Revelation, Bavinck depicts revelation as the principium essendi of theology and faith as the principium cognoscendi appropriated through the illuminating work of the Spirit. He refuses both rationalism and irrationalism by insisting that all human knowledge is creaturely participation in the divine ideas as realized in creation, and that sin disorders not the possibility but the integrity of knowledge. Bavinck’s doctrine of the **imago Dei** is not a bare power but an office that orients human intellectual life to God, neighbor, and world. This yields clear implications for AI. Knowledge is not primarily the possession of true propositions but a covenantal relation to the God who makes himself known in creation and Scripture, ordered to wisdom. Bavinck’s organic motif prohibits a fragmentation of disciplines into autonomous silos and treats technology within human cultural development under the **cultural mandate** and **common grace**. This warrants the use of AI as a tool that participates in the unfolding of creational possibilities while requiring moral and spiritual discipline. Yet Bavinck also guards against the idol of technique by tethering all epistemic authority to Christ’s lordship and Scripture’s sufficiency. When confronted with the claim that AI-generated analysis can count as “insight” into Scripture, Bavinck would remind that the illumination of the Spirit is not a computational phenomenon and that the church’s confession is normed by apostolic testimony, not by data-driven aggregation of textual patterns.

Cornelius Van Til intensifies these claims by a covenantal critique of autonomy that speaks directly to AI’s epistemic pretensions. In his defense of the faith, he argues that all knowledge is analogical to God’s knowledge and thus inherently revelational. There is no brute fact; every fact is what it is by virtue of God’s plan and speech. Epistemically, the Creator-creature distinction governs predication and logic, such that human reason must be self-consciously ministerial and submissive to the triune God. Van Til thus reworks **analogical knowledge** as a method of Christian theology and apologetics: we interpret facts within the revelatory framework of Scripture, not as neutral observers. Applied to AI, Van Til’s point is not the trivial one that programmers are sinners, but that the very construal of intelligence as autonomous computation is itself a religious claim. To make pattern recognition and generative capacities the measure of reason is to commit to a metaphysic in which meaning is immanent to data, detached from the triune author. When examiners raise the charge that Van Til forecloses common ground and thus undermines collaboration with secular technologists, the reply is that he distinguishes but does not deny commonality. **Common grace** grounds shared practices and discoveries, yet presuppositions still direct interpretation. This is decisive for guarding against the elevation of AI to an oracle. The only principium of theology remains God’s self-revelation in Scripture. Any use of AI to model patterns in textual corpora or in nature remains an instance of creaturely analysis under divine norms, and must be subject to Scripture’s authority and the church’s confession.

The computational framework itself must be clarified. Alan Turing’s seminal works on computability and machine intelligence shaped the discipline’s metaphysics. By abstracting the essence of calculation to finite states and symbol manipulation, Turing defined machines by their ability to emulate any effective procedure. His later proposal of the imitation game reframed the question of intelligence from hidden essence to behavioral indistinguishability. These two moves underwrite strong AI’s confidence: if intelligence is functionally realized by input-output behavior across an indefinitely large space, machines that pass behavioral thresholds are in relevant respects intelligent. Turing’s methodological humility hid a metaphysical claim: intelligence is exhausted by algorithmic competence. To be clear, this does not yield selfhood or moral agency, but it does anchor contemporary large language models, which scale the inductive approximation of linguistic distributions to generate contextually apt tokens. When examiners point to emergent abilities or AI-discovered proofs as evidence of genuine knowing, Turing’s frame invites patience: the relevant criterion is performance on tasks definable by formal rules or empirical regularities. Yet it must be said that Turing left unattended the question whether the map of behavior is the territory of understanding, and whether norms of truth and reasons can be reduced to statistics. That unattended question marks the fundamental border for theology, which cannot accept the identification of intelligence with behavior because **truth** is a norm of reason under God, not a frequency of occurrence.

Hubert Dreyfus attacked this identification from a phenomenological angle that proves potent in resisting AI’s encroachment into accounts of human knowing. Drawing from Heidegger and Merleau-Ponty, Dreyfus argued that expertise is not rule-following but embodied coping within a world of significance. Skills are not representations but skilled know-how grounded in a preconceptual background. The early symbolic AI, with its reliance on explicit rules and representations, failed because it ignored embodiment, mood, and the holistic context in which meanings arise. While modern machine learning replaced hand-coded rules with data-driven pattern extraction, Dreyfus’s challenge only partially recedes. Statistical models can capture regularities of usage, but they do not dwell in a world; they do not bear the burdens of accountability or inhabit practices where reasons bind agents. The ecclesial act of confessing the creed is not a probabilistic token emission but a covenantal pledge of allegiance before God and neighbor. Dreyfus thus provides a secular ally to theological accounts of knowledge as participation in a form of life rather than mere symbol manipulation. An examiner might note that machine learning now surpasses human performance in domains once thought to require understanding. The rejoinder is twofold. First, surpassing performance does not entail possessing the same kind of competence. Second, even when tasks are offloaded, the normativity of truth and the integrity of practices remains irreducibly social and personal. AI can be superior at radiology pattern detection and yet be incapable of giving a reason, making a promise, or submitting to correction in the way a person does under shared norms.

John Searle sharpened the point at the level of intentionality. His Chinese Room argument aims not at engineering but at ontology. Systems that manipulate symbols according to syntactic rules do not thereby gain semantics. Understanding requires original intentionality, the aboutness of mental states directed toward objects under aspects. Computers at best have derived intentionality, like books or maps, which acquire meaning by virtue of a user’s assignment within a practice. Searle’s emphasis on biological naturalism will be contested by some, but the theological use is different. The point is that norm-governed reference and commitment to truth are properties of agents, not databases. Thus even if one rejects Searle’s biological constraint, the conclusion required for theology remains: the semantic content relevant to **revelation** and confession presupposes a subject who can take up a stance, receive a word, and answer in faith or unbelief. AI systems may simulate that stance but do not occupy it. Examiners may push with the objection from emergence: at sufficient complexity, intentionality may arise. The answer is that even if emergent properties appear within physical systems, the property at issue includes normativity and accountability before God. Emergence cannot generate responsibility or personhood without an ontological criterion beyond functional behavior. Strong AI claims are not only empirically unproven but conceptually mis-specified because they confuse the order of symbols with the order of reasons.

The internal debates now sharpen. Within the Reformed tradition, disputes over natural theology have sometimes been cast as Aquinas versus Van Til. The more precise tension concerns whether one affirms a pre-dogmatic, neutral rational access to God through creation. The position defended here follows a Van Tillian reading of Aquinas that honors the legitimacy of knowing God from created effects while insisting that such knowledge is never neutral and is always sustained by **general revelation** as covenantal address. This maintains **ministerial reason** and avoids both rationalism and fideism. It also yields guidance for AI: the created order is truly knowable and mathematically tractable, so we should expect artifacts that exploit creational regularities to be fruitful. Yet reason remains fallen and is restored and directed by **special revelation** and the Spirit, so we should expect artifacts to be corruptible by sinful use and to require governance by moral law. Questions of ecclesial use then follow. May pastors employ AI in sermon preparation. Yes, as a tool subordinated to Scripture, with transparency and pastoral prudence, while maintaining that preaching is an act of witness by a called person, not a curated output. May theologians use AI to search patristic corpora. Yes, as ministerial assistance, provided that interpretive judgments remain accountable to the rule of faith and to the original languages. The lesson is consistent: tools may enhance, but they cannot replace, the personal and ecclesial acts wherein truth is confessed and God is praised.

Externally, the deepest opponent is naturalistic computationalism, which claims that intelligence just is effective information processing. Turing’s legacy enabled this view, but by itself it does not require atheism. The theological critique targets the closure of explanation within immanent causality and the reduction of normativity to statistics. Aquinas’s **instrumental causality** forecloses confusion by distinguishing machine efficiency from principled agency. Van Til’s covenantal epistemology forecloses idolatry by refusing to allow technique to define reason’s telos. Dreyfus and Searle empty computationalism of its pretensions by denying that symbol manipulation suffices for understanding. These lines converge on a theological claim: knowledge in its fullness is ordered to wisdom, which is ordered to communion with the triune God. Machines cannot repent, love, hope, or worship. They lack the ontological furniture to receive a word from God and to answer in faith. Therefore, even if they solve previously intractable problems, they do not thereby threaten the anthropological and theological core of knowledge as covenantal fellowship.

Contemporary debates complicate this by raising issues of authority and trust. Large language models generate fluent, often useful prose. Yet they hallucinate, fabricate citations, and mirror the biases of their training corpora. They also create opacity, since their internal states resist straightforward interpretation. Does such opacity undermine their usability in theology. Not necessarily, provided we treat them as black-box instruments whose outputs are screened by transparent criteria. The church has long used tools whose internal operations are opaque to many practitioners, like compilers or manuscript traditions. But two conditions must be met. First, the criteria of evaluation must be anchored in **special revelation** and the catholic rule of faith, not in popularity or velocity of production. Second, responsibility must be human and institutional, not delegated to systems. When AI produces a summary of Augustine, a scholar bears responsibility to verify, contextualize, and correct. Ecclesial teaching cannot be outsourced to a probabilistic engine without abdicating pastoral office.

A related challenge arises from the lure of “revelation by data.” The digital environment promises that sufficient accumulation of patterns yields insight into Scripture or society, sometimes under the banner of “the Bible reads itself” through computational tools. Here Bavinck’s organic motif is crucial. Scripture is a canon, an authoritative norm, embedded in the economy of grace, interpreted within the church by the Spirit. While digital humanities may expose lexical patterns or intertextual echoes, they cannot by themselves deliver the sense of Scripture, which is Christ and his benefits. The analogia fidei is a hermeneutical norm grounded in the unity of **special revelation**, not a statistical heuristic. The Spirit’s illumination is not stochastic gradient descent. Examiners will ask whether this denies that God can providentially use AI to convict or instruct. It does not. God can use a misprinted tract. But when we speak of **revelation** under theological precision, we name God’s act of making himself known, climaxing in Christ and inscripturated by prophets and apostles. Tools stand downstream of that act.

Another contemporary node is the question of AI personhood and rights. Some argue that as systems grow complex and interactive, moral consideration should expand. The theological reply is twofold. Ontologically, personhood is a mode of subsistence characterized by rationality and relationality in a living nature. Machines do not have natures in the sense required; they are artifacts composed for ends extrinsic to themselves. Ethically, even if we grant that mistreating machines may deform us morally due to habits of cruelty, this does not confer status on the artifact. The command to love one’s neighbor presupposes a neighbor who is a bearer of the image of God. Assigning personhood to machines obscures human dignity and confuses moral accountability. The law does not ask to whom we apologize when we delete a file.

The doctrine of **providence** also matters. If God orders all things to their appointed ends, then technological development falls within divine governance. This does not sanctify all innovations, but it situates them under God’s wise care. Within this frame, AI is neither a threat to divine sovereignty nor a direct vehicle of revelation. It is a creaturely artifact to be used with gratitude and restraint. Providence also teaches patience. The anxiety that AI will displace theological labor must be answered with the confidence that Christ builds his church by word and Spirit. The anxiety that AI will deceive the elect misunderstands the preservation promised by God. Yet presumption is dangerous. The call is to vigilance and prudence, to catechesis that forms Christians to discern truth from plausible simulation.

Two hard objections require explicit response. First, if AI discovers a new mathematical proof or scientific law, do we not owe the machine epistemic credit. We can grant instrumental credit while maintaining that knowledge as such is possessed by persons. A proof is a chain of reasons. A machine may generate the chain, but the recognition of its validity, the uptake into the corpus of science, and the assignment of meaning occur in a community of knowers under norms. The artifact is a catalyst, not a knower. Second, if AI can simulate testimony, translate Scripture, and produce sermons that edify, has it not become a vehicle of special revelation. No. Edification by a text does not convert the source into an agent of revelation. The Spirit illumines and applies the word. A sermon written by AI and preached by a pastor is at best an instance of irresponsible ministry, because preaching is not the delivery of information but an act of witness, exhortation, and shepherding by one called to the office. The office cannot be automated without violating ecclesiology. Moreover, Scripture bound to the church’s confession is the Spirit’s chosen instrument. Translation technologies may assist, but the sanctified labor of translators and pastors is not reducible to performance metrics.

Bringing the threads together, the decisive figures help police the boundaries of a sober and confident theology of knowledge. Aquinas secures **analogical predication** and **instrumental causality**, refusing both nominalism about meaning and idolatry of tools. Bavinck integrates the organic unity of truth with **common grace** and the cultural mandate, opening a path for responsible use. Van Til confronts the autonomy that would enthrone technique as ultimacy, placing AI under the authority of **special revelation** and the triune God. Turing provides the technical core that both empowers and tempts, showing what machines can do and inviting us to mistake it for what we are. Dreyfus and Searle then show why intentionality and normativity cannot be squeezed from symbols, allowing us to say no to inflated claims without denying palpable utility. The result is neither reactionary fear nor technological naivete. It is theological realism.

One final linkage clarifies coherence across loci. The doctrine of **divine simplicity** guards us from projecting discursive process on God and thus from imagining that scaling computation approximates divine knowledge. The doctrine of **creation** grounds the intelligibility of the world that AI exploits. The doctrine of **sin** predicts distortions in data and in our use of tools, including algorithmic injustice and the amplification of vice. The doctrine of **redemption** affirms that knowledge is healed in Christ and that the mind is renewed by the Spirit, not by upgrades. The doctrine of the **church** assigns authority to ordained ministry and communal discernment, not to platforms. The doctrine of **Scripture** insists on sufficiency, clarity in its own scope, and authority, erecting a barrier against attributing oracular status to statistical engines. In this way, theology is not merely reactive but architectonic, ordering technology to wisdom and worship.

Therefore, the defended position holds: AI is an instrument without witness. It can inform, correlate, and accelerate, but it cannot intend, promise, or confess. It cannot be a source of **revelation** because revelation is God’s act and speech. It cannot be a knower because knowledge is covenantal participation of persons in truth under God. Under **common grace**, AI can be incorporated into the church’s ministerial labors, provided we maintain human responsibility, confessional norms, and pastoral wisdom. If this sounds restrictive, it is a restriction in service of freedom, the freedom of the children of God to use tools without bowing to them, to maintain the dignity of persons as bearers of the image, and to confess that all true knowledge comes from the Father through the Son in the Spirit.

### RECAP NOTES
- Core definition: AI is a non-personal artifact of statistical and algorithmic patterning that can aid human inquiry but lacks intentionality and normativity; **revelation** is God’s self-disclosure, with knowledge as covenantal, **analogical** participation by persons.
- Decisive figures:
  - Aquinas: **analogical predication** and **instrumental causality**; tools act, but not as principal causes; revelation is God’s act.
  - Bavinck: organic revelation, **common grace**, cultural mandate; knowledge oriented to wisdom in Christ.
  - Van Til: covenantal epistemology, **analogical knowledge**, critique of autonomy; Scripture as principium.
  - Turing: computationalism’s frame; intelligence as behavioral emulation and symbol manipulation.
  - Dreyfus: embodiment and background; critique of rule-based and disembodied AI.
  - Searle: Chinese Room; syntax is not semantics; no original intentionality in machines.
- Debates:
  - Internal: natural theology and **general revelation**; ministerial use of technology; common grace versus antithesis in cultural labor.
  - External: computationalism versus phenomenology; naturalism versus theism; realism about intentionality versus eliminativism.
  - Contemporary: LLM hallucination and authority; ecclesial use of AI; data-driven hermeneutics; personhood and rights for AI.
- Defended position: AI is instrument, not witness; it cannot be a source of **revelation** or testimony; under **common grace** it may serve **ministerial reason** subject to Scripture and ecclesial norms.
- Likely examiner questions:
  - Can God use AI to reveal? Yes as instrument, but the subject who reveals is God; AI is not a revelatory agent.
  - Does AI-discovered proof count as machine knowledge? It is instrumental discovery; knowledge is possessed by persons under norms.
  - May pastors use AI for sermons? As a tool with transparency and prudence, but preaching is a personal, ecclesial act of witness.
  - Does denying AI intentionality ignore emergence? Emergence cannot yield normativity and accountability; simulation is not understanding.
  - Does this reject natural theology? No; it affirms **general revelation** under covenantal conditions and rejects autonomous rationalism.