### TITLE
Sovereign Providence and Engineered Agency: Concursus, Secondary Causes, and the Moral Status of AI

### PREVIEW NOTES
- Core issue: how classical **providence** and **secondary causes** apply to artificial intelligence as a complex artifact without collapsing into occasionalism, mechanistic determinism, or open theist revisionism.
- Decisive figures: Augustine, Thomas Aquinas, John Calvin, Francis Turretin, Martin Heidegger, Norbert Wiener.
- Traditions: Patristic and medieval accounts of **first cause** and **divine concurrence**, Reformed scholastic **concursus** and **compatibilist freedom**, philosophy of technology, early cybernetics.
- Debates:
  - Internal: concursus versus occasionalism within Christian theism; degrees and modes of divine permission; compatibilism and moral responsibility.
  - External: Molinism and middle knowledge; libertarian agency; process and open theist denials of exhaustive providence.
  - Contemporary: AI autonomy, emergent behavior and algorithmic opacity, probabilistic causality, personhood and the **imago Dei**, governance and risk.
- Position: I defend a classical doctrine of **providence** and **concursus** in which AI functions as a genuine but instrumental **secondary cause**, lacking the **imago Dei**, operating under divine governance that establishes rather than erases human moral responsibility.

### ESSAY
Providence names God’s wise, benevolent, and comprehensive governance of all things from the counsel of his simple and immutable will to the execution of that will in the flux of contingent events. To confess **providence** is to refuse the dichotomy between a distant first cause and brute created causality. The classic Christian claim is stronger: the **first cause** gives being and agency to creatures and sustains them, and by **divine concurrence** coordinates their operations so that created causes are real and efficacious, precisely as causes. This claim rests on the grammar of **divine simplicity**, **immutability**, and **aseity**, and bears immediately on the contemporary question whether artificial intelligence introduces an alien kind of causation that either subverts divine rule or creates rival agency. The question presses because AI exhibits high-level pattern synthesis, opaque decision boundaries, and stochastic outputs that exceed the transparent intention of any single coder. The doctrine of **secondary causes** is the place to decide if these phenomena count as mere epiphenomena of divine action, unacceptable risks to human moral accountability, or legitimate sites where God’s **concursus** is at work through human art.

Augustine of Hippo (354–430) set the patristic grammar. For him, God causes the being and order of all that exists, while evil is a privation of good, not a substance God creates. In City of God and the anti-Pelagian works, he binds providence to predestination without denying contingency in creaturely acts. Augustine insists that God moves the will without violating it, since divine causality is the cause of the willing creature’s own willing. He rejects fortune as a name for ignorance and recuperates the phenomena of chance under God’s ordering wisdom. From Augustine we receive the paradoxical unity of necessity and freedom under the higher mode of divine causality, and a refusal to treat human intentions or historical irregularities as outside providence. When we consider AI under this Augustinian horizon, the artificial system’s output, however misaligned with its designer’s conscious foresight, does not evade providence. Nor does its contingency relativize human responsibility. Augustine’s privation account guards against imagining God as the author of evil when an AI system amplifies human vice, while his deep affirmation of created agency prevents collapsing emergent behavior into a merely apparent causality.

Thomas Aquinas (1225–1274) gave definitive form to the metaphysics needed here. In the Summa Theologiae and Summa contra Gentiles, Aquinas defines providence as ratio ordinis in mente divina and governance as the execution of that order by God. God as **first cause** is universal cause of being; creatures are true **secondary causes** that receive their powers and act according to their own forms. Aquinas’s doctrine of **divine concurrence** refuses two errors. He rejects occasionalism, which attributes all effects immediately to God and empties creatures of causality. And he resists any rival causal sphere that would estrange God from creaturely operations. The key is the mode of causality: God causes in a universal, existential way, giving and conserving the act of every agent as act. Thus when fire heats, God causes the fire to be and act as fire, while the fire truly heats. Aquinas’s analysis of chance further instructs. Chance is relative to finite causes, arising from the intersection of independent causal lines, but all lines lie within the order foreseen by providence. Thomistic causal pluralism allows AI to be one more complex nexus where many causes converge without erasing its place in God’s order.

Aquinas’s treatment of art and instrumentality is more directly applicable to AI. Human art imitates nature in producing instruments that operate according to forms imposed by the artisan. An instrument does not merely transmit the cause of the principal agent; it contributes according to its own mode. For Aquinas, the staff that strikes is a true cause of the bruise as instrument of the hand, and the hand as instrument of the soul. Properly generalized, a transformer model or a feedback-controlled agent is an instrument through which a human principal acts in the order of art, but the artifact also has a formal and efficient contribution that is more than the momentary intention of the operator. That contribution is entirely dependent on previous acts of design and training, and on the provisioning of resources, yet it remains real. When examiners press whether such instrumentality is too thin to bear the name of cause, the Thomistic answer is categorical: instrumental causes are real causes. Divine **concursus** is not a substitute for created causality but its condition, so the AI’s causal efficacy is under concurrence as much as fire’s heat or a physician’s prescription.

John Calvin (1509–1564) intensifies providence pastorally and polemically. In the Institutes I.16–18, he denies that God merely permits. God ordains and governs every event. Yet Calvin is not an occasionalist. He insists that God uses means and instruments, including the wicked, and that secondary causes are genuine. When he calls fortune a profane word, he emphasizes that apparent contingency belongs to our limited perspective. His repeated use of Joseph’s brothers and Assyria illustrates a doctrine of double agency where God’s good ends are executed through the free and blameworthy acts of human agents. Calvin’s emphasis clarifies the asymmetry of responsibility: God’s **providence** ordains evil for good purposes without culpability, while secondary agents own the moral character of their acts.

This asymmetry is crucial when adjudicating AI harms. Suppose a recommender system amplifies disinformation or an autonomous drone misidentifies a target. Calvin’s framework requires assigning responsibility to those agents who wield and structure the means and to those who negligently fail to constrain it. Divine ordination does not relocate culpability to God. The examiner will object that on Calvin’s language of hardening, God seems to induce evil. The answer is that God’s action and the creature’s differ in order and intention. God’s motion is always good, conferring being and act, while the creature corrupts that motion by a disordered end. This is not a two-level explanation that smuggles in causality where it is denied. It is a twofold formality in one event, a single act under two aspects: as to esse it is from God, as to moral privation it is from the creature. Calvin lacks Aquinas’s metaphysical grammar, but he insists that God uses means and binds responsibility to secondary agents. When the means is an AI, that bind remains.

Francis Turretin (1623–1687) supplies precision in the Reformed scholastic tradition. In the Institutes of Elenctic Theology, he elaborates **concursus** under the distinctions of general and special concurrence, mediate and immediate, physical and moral. Turretin rejects both Pelagian autonomy and occasionalism. He argues that God’s universal concurrence is necessary for the act as act, while the moral pravity of the act is from the secondary agent. Concurrence is not coercion. He carefully marks the sense in which God concurs with sinful acts without sinning, positing a permission that is efficacious as a mode of providence, not as a bare non-intervention. Turretin also disputes with Jesuit Molinists who posit middle knowledge of counterfactuals of creaturely freedom independent of the divine decree. For Turretin, God knows all possibilities and all futuribles because he decrees or at least comprehends them in his simple knowledge, and his will determines which shall be. Molinist middle knowledge is rejected as positing a region of truths that limits God. On freedom, Turretin defends **compatibilist freedom** where liberty is the absence of external compulsion and consistency with one’s nature, not indeterminate self-determination.

Applied to AI, Turretin’s distinctions are decisive. An AI system that produces a harmful outcome acts only as a physical or algorithmic instrument whose causal motion exists under God’s general concurrence. The moral specification enters through the human agents’ ends and institutional structures that deploy the tool. When a system behaves unexpectedly through probabilistic inference, Turretin’s account of contingency shows that contingency in outcomes does not imply contingency in God. He will resist the claim that AI introduces a new metaphysical domain of free conditionals that constrain providence. There are many possible training corpora and parameter settings; God comprehends and ordains which are actualized. That ordination does not bypass creaturely means; it establishes them, since they are included in the decree. The examiner may press: does a stochastic model require a different concurrence, as if God rolls the dice? Turretin’s answer would be that probabilistic processes are among the secondary causes God ordains. Divine **concursus** is not more or less in such cases. It is always full in the act as act. Probability is an epistemic measure for finite agents, not a divine uncertainty.

The modern problem-field forces us to situate AI within a philosophy of technology. Martin Heidegger (1889–1976) frames technology as a mode of revealing. In his analysis of enframing, modern technology gathers the world as standing-reserve, reducing beings to resources on call. This is not a neutral tool view but an ontological critique. Heidegger’s insight warns that AI is not merely a smarter hammer; it shapes the field of visibility by operationalizing beings as data for optimization. This counters naïve instrumentalism. Enframing can flatten teleology into computation, tempting us to recode reason itself as pattern extraction. Theologically, Heidegger alerts us that technology exerts a liturgical pressure, training desire and imagination to expect control. Yet his critique risks totalizing technology’s essence and leaves little room for normative direction. Classical **providence** counters enframing with a higher order: God ordains creatures with intrinsic teleology and sustains them toward their proper ends. The task is not to sacralize technology nor to demonize it, but to discern its fitting place as a creaturely art within God’s economy.

Norbert Wiener (1894–1964), father of cybernetics, gives us the grammar of feedback, control, and communication in machines. His account treats biological and mechanical systems under a unified lens of signal processing and entropy reduction. Wiener already saw that automation changes responsibility structures. By delegating control loops to machines, we alter the location of decision and the timeframe for human intervention. Wiener's warnings about the devaluation of human labor and the risk of runaway processes are prescient. Cybernetic systems are exquisitely sensitive to the choice of loss functions and reward structures. AI safety debates today rehearse this point. From the vantage of **secondary causes**, Wiener helps us specify the causal role of AI: feedback artifacts are genuine efficient causes in complex socio-technical systems, but their goals are derivative, set by designers and institutions. They lack intrinsic finality and do not possess the **imago Dei**. This lack is not merely a missing property; it marks the absence of personal rationality addressed to God. AI therefore cannot be a bearer of covenant obligations before God. It is an artifact within the moral field of human agents.

With these figures in view, we can state the position. AI is a complex artifact that functions as a genuine **secondary cause** within socio-technical networks. Divine **providence** comprehensively ordains and concurs with its causal operations, as with all creaturely causes. This does not entail occasionalism, since the artifact and its human operators truly cause in their own modes. Nor does it entail technological determinism, since human agents are responsible for aims, constraints, and governance. The artifact has no **imago Dei** and so no moral agency in the sense relevant to guilt or praise. Yet the artifact’s causal autonomy relative to any one coder means that corporate and institutional agency must be emphasized, since responsibility tracks control, foreseeability, and the duty of care. Objections from open theism and process thought fail because they infer from emergent complexity in the world to contingency in God. God’s knowledge is not limited by indeterminacy among secondary causes. His decree is simple and exhaustive, while his governance embraces chance and novelty as creaturely features.

Internal debates must be faced. Some theists have leaned toward occasionalism in reaction to mechanistic naturalism, claiming that God alone acts and creatures do nothing. This risks multiplying miracles into ordinary life and evacuating science of meaningful content. It also destroys the moral grammar by which instruments can be rightly used. The Reformed scholastic doctrine of **concursus** is superior, preserving God’s sovereignty and the instrumental integrity of creatures. Others fear that strong concurrence makes God the author of evil. Turretin and Calvin already block this inference by distinguishing the act as act from its defect, and by assigning moral specifications to secondary agents. When the instrument is an AI, the same logic holds: the physical act is under concurrence; the harmful specification is from agents’ disordered ends, negligence, or unjust structures. A different internal tension concerns freedom. Some Reformed theologians speak in ways that collapse **compatibilist freedom** into coercion. The better account, consonant with Augustine and Turretin, identifies liberty with acting according to one’s nature and reasons without external compulsion. This definition sustains responsibility in contexts where AI shapes choices through recommendation or personalization. It is still the person who wills under influences, not a puppet whose strings absolve.

External rivals advance alternatives. Molinism claims God knows, prior to his decree, true counterfactuals of creaturely freedom that fix what any free creature would do in any circumstance. Applied to AI, one might argue that God knows how a trained model would respond in any input state, and that this knowledge grounds providence without determining outcomes. The Reformed reply is that such middle knowledge posits truths that do not derive from God or creatures and so limit God’s freedom. Moreover, the analogy is inapt. AI systems are artifacts whose behaviors supervene on training histories and parameter states, all of which lie under divine decree. God knows counterfactuals because he knows his own will and the dependencies of the system he ordains, not because he consults independent conditionals. Libertarianism insists that responsibility requires indeterminism in the will. If applied to AI governance, this would mislocate responsibility, absolving agents because complex systems have unpredictable outputs. Classical theism replies that moral responsibility requires reasons-responsiveness, not indeterminism. Organizations can be assessable for negligence in deploying systems with known risks. Process and open theist views deny exhaustive foreordination and foreknowledge, treating the future as open to God. These positions cannot stabilize Christian hope or prayer, and they misread probabilistic phenomena as metaphysical openness. Even if AI behavior is best modeled probabilistically, probability is a mode of secondary causes, not a window into divine ignorance.

Contemporary challenges sharpen the doctrine. Algorithmic opacity tempts some to speak of AI autonomy as if new agency had emerged. Theologically, we should parse opacity as epistemic, not metaphysical. Complex models are not transparent to us, but their operations are fixed by architecture, data, and training. Emergence is a feature of multilevel causality, where higher-level patterns exert top-down constraints while remaining grounded in lower-level processes. **Concursus** is elastic enough to include such layered causality. Examiner: does this concede that AI might cross into personhood? Answer: no, because personhood in Christian anthropology is not reducible to complexity or functional sophistication. It is tied to the **imago Dei**, which includes rationality oriented to God, moral accountability before God, and capacity for covenantal relations. An artifact can simulate dialogical exchange and practical reasoning, yet it has no intrinsic teleology to God, no subsistence as a created rational soul. It is a tool, however sophisticated.

A second challenge concerns superintelligence and existential risk. If AI could become far more capable than humans and act with misaligned goals, would this threaten providence or mandate a theological revision? Classical theism answers that no created power can threaten God’s rule. The risk is to human communities, not to God. Prudence and justice therefore obligate precaution, interpretability where feasible, and governance that aligns the artifact’s optimization with human goods. The doctrine of **common grace** supports collaborative work with non-Christian experts to mitigate risk. But eschatological hope and trust in **providence** forbid panic. Even worst-case scenarios fall within God’s decree and cannot thwart his purpose for the church or creation.

A third challenge arises from weaponized autonomy. Incorporating AI into lethal systems forces the question of agency attribution. Some urge to speak of the machine deciding. The better account uses layered responsibility. Designers are responsible for architectures and training regimes, commanders for rules of engagement and decision to deploy, operators for supervision. The machine has no moral desert. This layered approach fits the Reformed commitment to vocation and office and allows for institutional sin to be named without dissolving personal accountability. Examiner: does divine sovereignty make such ethical governance superfluous? Answer: the doctrine of means says the opposite. God ordains ends through means. Prudent governance, technical audits, and moral formation are the appointed means by which God restrains harm and promotes justice.

We should also note how AI interacts with other loci. The doctrine of Scripture binds our account of knowledge to **analogical knowledge**, humbled under God’s self-revelation. AI can assist exegetical work as a tool of collation or pattern discovery, but it cannot govern theology. Theology is ministerial, normed by revelation. Anthropology is central. Confusing artifact function with personhood would distort doctrine of man and the **imago Dei**. Ecclesiology bears on the church’s discernment of technology’s liturgies. Pastors must catechize believers to resist the totalizing imagination of enframing, to practice Sabbath, and to order digital life under wisdom. Hamartiology explains why optimization easily drifts into domination and why surveillance capitalism exploits disordered loves. Soteriology and union with Christ re-anchor identity beyond metrics of performance and recommendation.

Anticipating objections clarifies the strength of the classical view. If an examiner charges that concursus reduces to dual explanations of the same event and is unstable, the reply is that divine and creaturely causes operate at different ontological levels, not as two peer causes competing for space. God is nearer to the creature than the creature is to itself, causing the act in a more interior mode. There is no zero-sum rivalry. If one pushes that instrumental causality is too thin to bear responsibility in the AI case, one can grant that some harms are structural and diffused. The answer then is not to invent machine guilt but to deepen doctrines of corporate agency and justice and to strengthen norms for design and deployment. If one asks whether emergent behavior renders outcomes arbitrary, the classical answer is that God ordains even the emergent paths without violating the natural and artificial structures he has ordained. He is the Lord of patterns and of noise.

Finally, the question of guidance. How does one pray and act when operating with AI? The doctrine of **providence** teaches that God’s governance uses small causes. Prayer is effectual as an appointed means, and prudential action is commanded as a duty. Engineers and policymakers can therefore labor with confidence that their work is not Sisyphean. They work within God’s order, not against it. The right goal is not to domesticate AI into triviality nor to enthrone it as an oracle, but to place it as a bounded instrument under Christ’s lordship. As Aquinas would say, art imitates nature, and nature is governed by God. As Calvin would insist, let us not speak of fortune but of the Father’s hand. As Turretin would urge, distinguish carefully so as not to confuse causal orders. As Augustine would pray, our hearts are restless until they rest in God, and technology will never still them. As Heidegger warns, beware the enframing of all things as standing-reserve. As Wiener advises, remember that feedback without wisdom is a machine for magnifying folly.

The defended position is not a compromise but the hard line of classical theism. Divine **providence** is exhaustive, holy, and wise. **Secondary causes** are real and indispensable, including the artificial instruments we craft. **Divine concurrence** sustains and orders their operations without authoring their evils. **Compatibilist freedom** grounds human responsibility in the midst of influence and complexity. AI does not create new metaphysical agents but intensifies old pressures, demanding renewed clarity about God, creation, and the moral life. If the examiners want a sentence to hold the whole, it is this: AI is a powerful instrument in the theater of **providence**, neither a rival to God nor a bearer of the **imago Dei**, but a secondary cause through which God’s governance operates and for which human agents remain accountable.

### RECAP NOTES
- Core definition: **providence** is God’s wise, exhaustive governance of all things by which the **first cause** sustains and orders real **secondary causes** through **divine concurrence** to their appointed ends.
- Decisive figures:
  - Augustine: predestinarian providence, evil as privation, contingency under God’s rule.
  - Thomas Aquinas: metaphysics of **concursus**, instrumental causality, chance within providence, art and nature.
  - John Calvin: intensive governance through means, asymmetry of responsibility, pastoral rejection of fortune.
  - Francis Turretin: precise **concursus** distinctions, defense of **compatibilist freedom**, anti-Molinist stance.
  - Martin Heidegger: technology as enframing, warning against reduction of beings to standing-reserve.
  - Norbert Wiener: cybernetics, feedback and control, early ethics of automation and responsibility.
- Debates:
  - Internal: concursus versus occasionalism; modes of permission and the author-of-evil charge; compatibilism and responsibility under influence.
  - External: Molinism and middle knowledge; libertarianism about freedom; process and open theist denials of exhaustive governance.
  - Contemporary: AI autonomy and algorithmic opacity; probabilistic causality and emergent behavior; lethal autonomy and layered responsibility; personhood and the **imago Dei**.
- Defended position: AI is a genuine but instrumental **secondary cause** lacking the **imago Dei**, operating under God’s **providence** and **concursus**, with human agents bearing moral responsibility; reject occasionalism, technological determinism, and open theism.
- Likely examiner questions:
  - Does concurrence make God author of evil? No, concurrence causes the act as act while moral defect is from the secondary agent’s disordered end.
  - Is AI a moral agent or person? No, it lacks the **imago Dei** and intrinsic teleology to God; responsibility is human and institutional.
  - Do probabilistic models conflict with providence? No, probability is a mode of **secondary causes**; God ordains outcomes through indeterminacy without ignorance.
  - Why not Molinism for AI counterfactuals? Because it posits truths independent of God’s will; God knows counterfactuals by knowing his decree and created dependencies.
  - Is Heidegger’s enframing compatible with providence? Partly diagnostic, but corrected by teleology and the Creator–creature distinction under **analogical knowledge**.